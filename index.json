[{"authors":["admin"],"categories":null,"content":"I am a statistician whose research involves methodological development, and is based largely on motivation from questions in the social sciences, social epidemiology and environmetrics.\nMy recent work is on statistical models for social networks, network inference, the development of statistical methodology for the collection and analysis of social network data, surveying of hard-to-reach populations, spatial processes and demography.\n","date":1655596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1655596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https:handcock.github.io/author/mark-s.-handcock/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/mark-s.-handcock/","section":"authors","summary":"I am a statistician whose research involves methodological development, and is based largely on motivation from questions in the social sciences, social epidemiology and environmetrics.\nMy recent work is on statistical models for social networks, network inference, the development of statistical methodology for the collection and analysis of social network data, surveying of hard-to-reach populations, spatial processes and demography.","tags":null,"title":"Mark S. Handcock","type":"authors"},{"authors":null,"categories":null,"content":"This course is an introduction to computational statistics through numerical methods and computationally intensive methods for statistical problems. Topics include statistical graphics, root finding, simulation, randomization testing, and bootstrapping. Covers intermediate to advanced programming with R.\nMotivation and Synopsis During the twentieth century, the development of statistical computing played a crucial facilitating role for the growth of the statistics discipline and the adoption of statistical methods within the scientiﬁc community and beyond. In the twenty-ﬁrst century digital age, the amounts of data available for statistical analysis has grown tremendously, yielding new opportunities for statistical computing, as well as new challenges. Statistical computing constitutes an important part of a statistics education, and is highly valuable for statisticians in both academia and industry.\nThis course is designed to provide the upper-division statistics student with the fundamentals of statistical computing, particularly through use of the language R.\nThe course is thematically split into two parts. The ﬁst part will focus on learning the tools and the necessary skills to perform computational statistics. Students will learn intermediate to advanced R programming and usage of some of its functions and packages. The student will learn how to develop functions and packages for the management, pre-processing and analysis of statistical data. The second part of the class will focus on some foundational methods in computational statistics. This includes numerical methods such as root ﬁnding, numeric integration, and mathematical optimization. It will continue on to cover the generation of random variables, simulation, and Monte Carlo methods to answer statistical questions.\nThe computer is the scientific laboratory of the statistician. It plays the same role for the statistical research as the traditional laboratories play for physics and chemistry researchers. As such this course should allow the student to develop a degree of comfort and competence \"in the lab.”\nThe primary purpose of this course is to provide students with a common set of core knowledge about statistical computing computing for their class work and research. The course will have an applied focus on tools. The course will involve the practical application of the ideas of statistical computing and their implementation through statistical software, particularly R.\nSyllabus of the Course Lecture \u0026nbsp;Topics 1 Introduction, the R language and eco-system 2 Data structures and their management 3 R programming and writing functions 4 Importing data, web scraping, manipulating data with tidyr and dpyr 5 Visualization and graphics (ggplot2) 6 Numerical methods: floating point arithmetic, root finding 7 Numerical methods: basic optimization 8 Random numbers, random variables, and simulation in R 9 Randomization tests, permutation tests and bootstrapping 10 Additional topics: Monte Carlo-integration, kernel density estimation A detailed description of the class is available here.\n","date":1479945600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1479945600,"objectID":"1dcdb082ac2522a88b8b327a6d86e8e2","permalink":"https:handcock.github.io/teaching/102a/","publishdate":"2016-11-24T00:00:00Z","relpermalink":"/teaching/102a/","section":"teaching","summary":"This course is an introduction to computational statistics through numerical methods and computationally intensive methods for statistical problems. Topics include statistical graphics, root finding, simulation, randomization testing, and bootstrapping. Covers intermediate to advanced programming with R.","tags":["courses"],"title":"STATS 102A: Introduction to Computational Statistics with R","type":"teaching"},{"authors":null,"categories":null,"content":"This course considers the impacts that data collected today have upon individuals and society. Rapid increase in scale and types of data collected has impacted commerce and society in new ways. Consideration of economic, social and ethical, legal and political impacts of data, especially that collected on human behavior. Topics include privacy and data protection, intellectual property and confidentiality, sample selection and algorithms, equality and anti-discrimination.\nThe Bruin Learn course page is here.\nMotivation and Synopsis During the twentieth century, the development of statistical computing played a crucial facilitating role for the growth of the statistics discipline and the adoption of statistical methods. In the twenty-first century digital age, the amounts of data available for statistical analysis has grown tremendously, yielding new opportunities , as well as new challenges.\nThis course considers the impacts that the data collected today have upon individuals and society. The rapid increase in the scale and types of data collected has impacted commerce and society in new ways. In this course we consider the economic, social and ethical, legal and political impacts of data, especially that collected on human behavior. Particular topics will be privacy and data protection, intellectual property and confidentiality, sample selection and algorithms, equality and anti-discrimination.\nThis course is intended to provide students sociological, psychological and economic lenses to explore how our increasingly digital lifestyle changes institutions and social relations. These lenses are then used to guide data scientists in their work.\nThe course has various parts:\nWe\u0026rsquo;ll consider what data is and the growth of Big Data. We will consider the role data play in the broader information context and how that context influences the data we collect and the related statistical issues. We will consider statistical techniques to improve privacy and data protection, confidentiality, sample selection and algorithms, equality and anti-discrimination. Syllabus of the Course Lecture \u0026nbsp;Topics 1 Introduction: What, really, is Data? 2 Contextualizing Data 3 Small Data and Big Data 4 Datafication and its Implications 5 Statistical methods to preserve privacy 6 Sample selection and algorithms 7 Equality and anti-discrimination\n8 Intellectual and Personal Property 9 Additional topics ","date":1641168e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641168e3,"objectID":"8c798203eccd3c08d0d609778cbefa37","permalink":"https:handcock.github.io/teaching/184/","publishdate":"2022-01-03T00:00:00Z","relpermalink":"/teaching/184/","section":"teaching","summary":"This course considers the impacts that data collected today have upon individuals and society. Rapid increase in scale and types of data collected has impacted commerce and society in new ways.","tags":["courses"],"title":"STATS 184: Societal Impacts of Data","type":"teaching"},{"authors":null,"categories":null,"content":"This course is a survey of computational methods that are especially useful for statistical analysis, with implementations in statistical package R. Topics include matrix analysis, multivariate regression, principal component analysis, multivariate analysis, and deterministic optimization methods.\nThe Bruin Learn course page is here.\nA detailed description of the class is available here.\nMotivation and Synopsis During the twentieth century, the development of statistical computing played a crucial facilitating role for the growth of the statistics discipline and the adoption of statistical methods within the scientiﬁc community and beyond. In the twenty-ﬁrst century digital age, the amounts of data available for statistical analysis has grown tremendously, yielding new opportunities for statistical computing, as well as new challenges. Statistical computing constitutes an important part of a statistics education, and is highly valuable for statisticians in both academia and industry.\nThis course is an introduction computational methods that are useful for statistical analysis, with implementations in the statistical package R.\nComputational methods are essential to both understand and implement modern statistical ideas. Often the computation methods are a translation of the statistical methods into another language, one that computer understand. In this class we will consider this process for key statistical models and techniques. These include multivariate regression, principal component analysis, and multivariate analysis. In doing so, we study the core mathematical and numerical ideas that make this possible including matrix analysis and deterministic optimization methods.\nThe course has various parts:\nWe\u0026rsquo;ll do some matrix algebra (not linear algebra), emphasizing what is available in R. We apply the matrix algebra to multivariate data analysis, in particular to regression, principal component analysis, canonical analysis, correspondence analysis. We discuss optimization methods. These will be mainly deterministic but also stochastic methods We finally apply both optimization and linear algebra to discuss statistical techniques such as multidimensional scaling, independent component analysis, tomography, and generalized mixed linear models. Well, maybe not all. The primary purpose of this course is to provide students with a common set of core knowledge about statistical computing computing for their class work and research. The course will have an applied focus on tools. The course will involve the practical application of the ideas of statistical computing and their implementation through statistical software, particularly R.\n","date":1650326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650326400,"objectID":"d3e2a7a48bf33e71880311b2406d69a4","permalink":"https:handcock.github.io/teaching/202b/","publishdate":"2022-04-19T00:00:00Z","relpermalink":"/teaching/202b/","section":"teaching","summary":"This course is a survey of computational methods that are especially useful for statistical analysis, with implementations in statistical package R. Topics include matrix analysis, multivariate regression, principal component analysis, multivariate analysis, and deterministic optimization methods.","tags":["courses"],"title":"STATS 202B: Matrix Algebra and Optimization","type":"teaching"},{"authors":null,"categories":null,"content":"This course is a survey of Monte Carlo methods and numerical integration. Importance and rejection sampling. Sequential importance sampling. Markov chain Monte Carlo (MCMC) sampling techniques, with emphasis on Gibbs samplers and Metropolis/Hastings. Simulated annealing. Exact sampling with coupling from past. Permutation testing and bootstrap confidence intervals.\nA detailed description of the class is available here.\nMotivation and Synopsis During the twentieth century, the development of statistical computing played a crucial facilitating role for the growth of the statistics discipline and the adoption of statistical methods within the scientiﬁc community and beyond. In the twenty-ﬁrst century digital age, the amounts of data available for statistical analysis has grown tremendously, yielding new opportunities for statistical computing, as well as new challenges. Statistical computing constitutes an important part of a statistics education, and is highly valuable for statisticians in both academia and industry.\nThis graduate level course introduces Monte Carlo methods for simulation, optimization, estimation, learning and complex landscape visualization, including: Importance sampling; Sequential importance sampling; Markov chain Monte Carlo (MCMC) sampling techniques including Gibbs samplers, Metropolis/Hastings and various improvements; Simulated annealing; Exact sampling techniques; Convergence analysis; Data augmentation; Cluster sampling, such as Swendsen-Wang and SW-cuts; Hamiltonian and Langevin Monte Carlo; Equi-energy and multi-domain sampler; and Techniques for mapping complex energy landscapes\nThe primary purpose of this course is to provide students with a common set of core knowledge about statistical computing computing for their class work and research. The course will have an applied focus on tools. The course will involve the practical application of the ideas of statistical computing and their implementation through statistical software, particularly R.\nPrerequisites\nStat 202B: Matrix Algebra and Optimization. People who didn’t take 202B before may still take this class as long as they have background on matrix algebra, probability theory, and programming skills. To do this attend the first classes and we can assess if this is advisable. ","date":1609632e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609632e3,"objectID":"f637e40bc86650f8c464d0e2bf95ad95","permalink":"https:handcock.github.io/teaching/202c/","publishdate":"2021-01-03T00:00:00Z","relpermalink":"/teaching/202c/","section":"teaching","summary":"This course is a survey of Monte Carlo methods and numerical integration. Importance and rejection sampling. Sequential importance sampling. Markov chain Monte Carlo (MCMC) sampling techniques, with emphasis on Gibbs samplers and Metropolis/Hastings.","tags":["courses"],"title":"STATS 202C: Monte Carlo Methods for Optimization","type":"teaching"},{"authors":null,"categories":null,"content":"This course is designed for social sciences graduate students and advanced undergraduate students seeking training in data issues and methods employed in social sciences.\nThe Bruin Learn course page is here.\nA detailed description of the class is available here.\nMotivation and Synopsis Statistics C116/C216 is a second course in social statistics and will focus on Bayesian statistical analysis. It will cover the principles of Bayesian statistics, Bayesian data analysis and modeling. In particular it will develop the ideas in the context of linear regression, its non-linear generalizations, and hierarchical models. While the idea and principles are general, all applications and models will be chosen from those most relevant to the social sciences.\nThis course is designed for graduate students majoring in Statistics, the Social Sciences and advanced undergraduate students who are planning to attend graduate school.\nThis course is most appropriate for student seeking additional training in the application of Bayesian statistics to data and are looking for an introductory course that advances rapidly. The ultimate goal is to equip students with the analytical and programming skills necessary to address social statistics problems within the Bayesian paradigm based on current data and technologies.\nThe course has various perspectives:\nIt focuses on conceptual understanding of the Bayesian statistics. It focuses on conceptual understanding of the the primary models used in social statistics. It involves the analysis of real-data. It involves implementing the methods using freely available software. The course will involve the practical application of the ideas of statistical computing and their implementation through statistical software, particularly R. As statistical computation is essential for many of the modeling approaches, expertise will need to be developed.\n","date":1633219200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1633219200,"objectID":"3b5439321bff995d19aac4394582e270","permalink":"https:handcock.github.io/teaching/c216/","publishdate":"2021-10-03T00:00:00Z","relpermalink":"/teaching/c216/","section":"teaching","summary":"This course is designed for social sciences graduate students and advanced undergraduate students seeking training in data issues and methods employed in social sciences.\nThe Bruin Learn course page is here.","tags":["courses"],"title":"STATS C216/C116: Social Statistics","type":"teaching"},{"authors":null,"categories":null,"content":"This course is a introduction to the analysis of social structure, conceived in terms of social relationships. Major concepts of social network theory and mathematical representation of social concepts such as role and position. Use of graphical representations of network information.\nA detailed description of the class is available here.\nMotivation and Synopsis This course is an introduction to the analysis of social structure, conceived in terms of social relationships.\nSocial structure is conceptualized as a system of social relations tieing distinct social entities to one another. Social network theory is the attempt to represent the structure in social relations via networks. It is then a theory pertaining to types of observable social spaces and their relation to individual and group behavior.\nObservations on the social relations are of two forms:\nindividual level information on the social entities relational data on pairs of entities While both forms are important for the study of social relations, social network theory recognizes fundamental role of the relational information. It is based on the premise that social context is an important determinant of individual behavior. It seeks to understand individual and group behavior in terms of relational information rather than as solely the aggregation of individual characteristics.\nThe focus of the course are modern methods for the statistical analysis of social networks. The course covers the major concepts of social network theory and the mathematical representation of social concepts such as \u0026ldquo;role\u0026rdquo; and \u0026ldquo;position\u0026rdquo;.\nVisualization plays a central in social network analysis. With the development of high speed computing and graphical display tools, visualization has become a flexible and powerful tool in the exploration of social relations. Graphics exploit the power of our visual senses to convey information in a direct way. In this course we will emphasize the use of graphical representations of network information as much as possible.\n","date":1601683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1601683200,"objectID":"eb697444bd01bb6aff69d23f225b215c","permalink":"https:handcock.github.io/teaching/218/","publishdate":"2020-10-03T00:00:00Z","relpermalink":"/teaching/218/","section":"teaching","summary":"This course is a introduction to the analysis of social structure, conceived in terms of social relationships. Major concepts of social network theory and mathematical representation of social concepts such as role and position.","tags":["courses"],"title":"STATS 218: Statistical Analysis of Networks","type":"teaching"},{"authors":[],"categories":null,"content":"","date":166014e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":166014e4,"objectID":"88ed911ff3614164e003063d50692934","permalink":"https:handcock.github.io/talk/jsm22/","publishdate":"2021-12-12T17:11:21Z","relpermalink":"/talk/jsm22/","section":"talk","summary":"This is an Invited Paper for the session 'Statistical Methods for Social Interactions — Invited Papers', 2022 Joint Statistical Meetings.","tags":[],"title":"Revealed Preference Models for Marriage Formation","type":"talk"},{"authors":[],"categories":null,"content":"","date":1659967200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659967200,"objectID":"1e4f8cf32d22bc92b3ae2b28df7f933e","permalink":"https:handcock.github.io/talk/duncan22/","publishdate":"2021-12-12T17:11:21Z","relpermalink":"/talk/duncan22/","section":"talk","summary":"This is the Duncan Invited Lecture, Section on Methodology, 117th American Sociological Association Annual Meeting.","tags":[],"title":"Revealed Preference Models for Marriage Formation","type":"talk"},{"authors":[],"categories":null,"content":"","date":1657756800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1657756800,"objectID":"e3ad8cac8438b03b071b6e99cf5adb87","permalink":"https:handcock.github.io/talk/sunbelt22-ensemble-lolog/","publishdate":"2021-12-12T17:11:21Z","relpermalink":"/talk/sunbelt22-ensemble-lolog/","section":"talk","summary":"We assess the real-world performance of Latent Order Logistic models (LOLOG) when applied to typical networks modelled by researchers by comparing them to Exponential-family random graph models (ERGMs). We demonstrate that the LOLOG models are, in general, in qualitative agreement with the ERGM models, and provide at least as good a model fit. In addition, they are typically faster and easier to fit to data, without the tendency for degeneracy that plagues ERGMs. This is joint work with Duncan A. Clark.","tags":["Degeneracy","ERGM","goodness of fit","LOLOG","social network analysis","social network modelling"],"title":"Comparing the real-world performance of exponential-family random graph models and latent order logistic models for social network analysis","type":"talk"},{"authors":["Bart Blackburn","Mark S. Handcock"],"categories":[],"content":"","date":1655596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655596800,"objectID":"365194bc789656eb4c0aad8bf9cef38a","permalink":"https:handcock.github.io/publication/tapering/","publishdate":"2022-06-19T00:00:00Z","relpermalink":"/publication/tapering/","section":"publication","summary":"Exponential-family Random Graph Models (ERGMs) have long been at the forefront of the analysis of relational data. The exponential-family form allows complex network dependencies to be represented. Models in this class are interpretable, flexible and have a strong theoretical foundation. The availability of powerful user-friendly open-source software allows broad accessibility and use. However, ERGMs sometimes suffer from a serious condition known as near-degeneracy, in which the model exhibits unrealistic probabilistic behavior or a severe lack-of-fit to real network data. Recently, Fellows and Handcock (2017) proposed a new model class, the Tapered ERGM, which circumvents the issue of near-degeneracy while maintaining the desirable features of ERGMs. However, the question of how to determine the proper amount of tapering needed for any model was heretofore left unanswered. This paper develops a new methodology for how to determine the necessary level of tapering and as such provides a new approach to inference for the Tapered ERGM class. Noting that a Tapered ERGM can always be made non-degenerate, we offer data-driven approaches for determining the amount of tapering necessary. The mean-value parameter estimates are unaffected by tapering, and we show that the natural parameter estimates are numerically weakly varying by the level of tapering. We then apply the Tapered ERGM to two published networks to demonstrate its effectiveness in cases where typical ERGMs fail and present the case for Tapered ERGMs replacing ERGMs entirely. Accepted.","tags":["Exponential-family Random Graph Model","Social Network Analysis","Degeneracy","Goodness-of-Fit"],"title":"Practical Network Modeling via Tapered Exponential-family Random Graph Models","type":"publication"},{"authors":[],"categories":null,"content":"","date":1654705800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1654705800,"objectID":"c74dd85a51056e48622362cd86d63a4b","permalink":"https:handcock.github.io/talk/itacosm22/","publishdate":"2021-12-12T17:11:21Z","relpermalink":"/talk/itacosm22/","section":"talk","summary":"This is an invited talk on survey sampling given at the 7th Italian Conference on Survey Methodology.","tags":[],"title":"Sampling Hard-to-Reach Populations","type":"talk"},{"authors":[],"categories":null,"content":"","date":1653984e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653984e3,"objectID":"4828a5be1b1f900dc40631ab7c8358e0","permalink":"https:handcock.github.io/talk/ssc-icmic22/","publishdate":"2021-12-12T17:11:21Z","relpermalink":"/talk/ssc-icmic22/","section":"talk","summary":"This is the Presidential Invited Address, Survey Methods Section, Statistical Society of Canada Annual Meeting.","tags":[],"title":"Sampling Hard-to-Reach Populations","type":"talk"},{"authors":["Duan Mengjuan","Mark S. Handcock","Bart Blackburn","Fiona Kee","Viema Biaukula","Tamano Matsuic","Babatunde Olowokurec"],"categories":[],"content":"","date":1653436800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653436800,"objectID":"1567c1dc9709c69d0c12bcec0de79a1a","permalink":"https:handcock.github.io/publication/who-acm-calc/","publishdate":"2022-05-24T21:28:45Z","relpermalink":"/publication/who-acm-calc/","section":"publication","summary":"A method was developed to track all-cause mortality (ACM) and an online open-source user-friendly interface was developed for its use.","tags":["All-Cause Mortality","Excess Deaths","Statistical Model"],"title":"Tool for tracking all-cause mortality and estimating excess mortality to support the COVID-19 pandemic response","type":"publication"},{"authors":[],"categories":null,"content":"","date":1653411600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653411600,"objectID":"1493b8a725a57bafdff651cfd5867096","permalink":"https:handcock.github.io/talk/intheworld2205/","publishdate":"2021-12-12T17:11:21Z","relpermalink":"/talk/intheworld2205/","section":"talk","summary":"This event provided an opportunity for students to hear from leading data scientists about how their world has been changed by data. They shared how a data scientist can be successful in any career area or industry. I was the moderator at this event.","tags":[],"title":"Data Theory in the World Seminar: How Data Drives Business Decisions","type":"talk"},{"authors":[],"categories":null,"content":"","date":1650564e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650564e3,"objectID":"b0b33203b9be7e000cf54220e5f390f7","permalink":"https:handcock.github.io/talk/alumni22/","publishdate":"2021-12-12T17:11:21Z","relpermalink":"/talk/alumni22/","section":"talk","summary":"This event provided an opportunity for alumni of the department to hear about work of department members on COVID-19 pandemic response.","tags":[],"title":"COVID through a statistical lens","type":"talk"},{"authors":null,"categories":null,"content":"After many years with a hand written website in HTML, I moved to using the Hugo framework with the Academic theme. The motivation for this is the work of Qingyuan Zhao who deserved the credit for both creating the template and also publishing it so that others can benefit from it. Thank you, Qingyuan Zhao!\n","date":1650412800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650412800,"objectID":"ee42c466b30f21ae7250698f994671a9","permalink":"https:handcock.github.io/post/migrating/","publishdate":"2022-04-20T00:00:00Z","relpermalink":"/post/migrating/","section":"post","summary":"After many years with a hand written website in HTML, I moved to using the Hugo framework with the Academic theme. The motivation for this is the work of Qingyuan Zhao who deserved the credit for both creating the template and also publishing it so that others can benefit from it.","tags":["Workflow"],"title":"Migrating my website to Hugo + Academic","type":"post"},{"authors":null,"categories":null,"content":"I am an affiliate of the California Center for Population Research at UCLA.\n","date":1650326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650326400,"objectID":"d57825f2e9246f4e0c9de3b14a0384e3","permalink":"https:handcock.github.io/research/ccpr/","publishdate":"2022-04-19T00:00:00Z","relpermalink":"/research/ccpr/","section":"research","summary":"I am an affiliate of the California Center for Population Research at UCLA.","tags":["courses"],"title":"CCPR","type":"research"},{"authors":["Marilyn N. Raphael","Mark S. Handcock"],"categories":[],"content":"","date":1646870400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646870400,"objectID":"58d88fb4430d0f8c931e8b38f9b87667","permalink":"https:handcock.github.io/publication/nature-min/","publishdate":"2022-03-10T21:28:45Z","relpermalink":"/publication/nature-min/","section":"publication","summary":"Antarctic sea ice extent reached a new record low of 1.965 million km2 on 23 February 2022. This extent is approximately 32% below climatological values and might indicate a transition to new, more extreme, annual fluctuations.","tags":["Climate Change","Environmetrics","Cryospheric science"],"title":"A New Record Minimum for Antarctic Sea Ice","type":"publication"},{"authors":["Duncan A. Clark","Mark S. Handcock"],"categories":[],"content":"","date":1643328e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1643328e3,"objectID":"8e3c60436a8e35f7e6c8738713d07b4d","permalink":"https:handcock.github.io/publication/ensemble-lolog/","publishdate":"2022-01-28T00:00:00Z","relpermalink":"/publication/ensemble-lolog/","section":"publication","summary":"We assess the real-world performance of Latent Order Logistic models (LOLOG) when applied to typical networks modelled by researchers by comparing them to Exponential-family random graph models (ERGMs).  We demonstrate that the LOLOG models are, in general, in qualitative agreement with the ERGM models, and provide at least as good a model fit.  In addition, they are typically faster and easier to fit to data, without the tendency for degeneracy that plagues ERGMs.","tags":["Degeneracy","ERGM","goodness of fit","LOLOG","social network analysis","social network modelling"],"title":"Comparing the real-world performance of exponential-family random graph models and latent order logistic models for social network analysis","type":"publication"},{"authors":["Ryan L Fogt","Amanda M Sleinkofer","Marilyn N. Raphael","Mark S. Handcock"],"categories":[],"content":"","date":1641772800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641772800,"objectID":"c9afea3f0d03b4c7a82d2ad44a1e84ea","permalink":"https:handcock.github.io/publication/nature-regime-shift/","publishdate":"2022-01-10T00:00:00Z","relpermalink":"/publication/nature-regime-shift/","section":"publication","summary":"In stark contrast to the Arctic, there have been statistically significant positive trends in total Antarctic sea ice extent since 1979. However, the short and highly variable nature of observed Antarctic sea ice extent limits the ability to fully understand the historical context of these recent changes. To meet this challenge, we have created robust, observation-based reconstruction ensembles of seasonal Antarctic sea ice extent since 1905. Using these reconstructions, here we show that the observed period since 1979 is the only time all four seasons demonstrate significant increases in total Antarctic sea ice in the context of the twentieth century and that the observed increases are juxtaposed against statistically significant decreases throughout much of the early and middle twentieth century. These reconstructions provide reliable estimates of seasonally resolved total Antarctic sea ice extent and are skilful enough to better understand aspects of air–sea–ice interactions within the Antarctic climate system.","tags":["Climate Change","Environmetrics","Cryospheric science"],"title":"A Regime Shift in Seasonal Total Antarctic Sea Ice Extent in the Twentieth Century","type":"publication"},{"authors":[],"categories":null,"content":"","date":1639065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1639065600,"objectID":"88d3682faa96cf413f9e527a755e5558","permalink":"https:handcock.github.io/talk/whotag22/","publishdate":"2021-12-12T17:11:21Z","relpermalink":"/talk/whotag22/","section":"talk","summary":"","tags":[],"title":"Tracking all cause of death and estimating excess mortality during the COVID-19 pandemic: statistical and computational tools","type":"talk"},{"authors":["Alex D. Fraser","Robert A. Massom","Mark S. Handcock"," P. Reid"," K.  I. Ohshima"," M. N. Raphael"," J. Cartwright"," A. R. Klekociuk"," Z. Wang","R. Porter-Smith"],"categories":[],"content":"","date":1635897600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635897600,"objectID":"24f89b18379ddc1e4bbcaa7fabafe1d1","permalink":"https:handcock.github.io/publication/fast-ice/","publishdate":"2021-11-03T00:00:00Z","relpermalink":"/publication/fast-ice/","section":"publication","summary":"Landfast sea ice (fast ice) is an important though poorly understood component of the cryosphere on the Antarctic continental shelf, where it plays a key role in atmosphere–ocean–ice-sheet interaction and coupled ecological and biogeochemical processes. Here, we present a first in-depth baseline analysis of variability and change in circum-Antarctic fast-ice distribution (including its relationship to bathymetry), based on a new high-resolution satellite-derived time series for the period 2000 to 2018. This reveals (a) an overall trend of −882±824 km2 yr−1 (−0.19±0.18 % yr−1) and (b) eight distinct regions in terms of fast-ice coverage and modes of formation. Of these, four exhibit positive trends over the 18-year period and four negative. Positive trends are seen in East Antarctica and in the Bellingshausen Sea, with this region claiming the largest positive trend of +1198±359 km2 yr−1 (+1.10±0.35 % yr−1). The four negative trends predominantly occur in West Antarctica, with the largest negative trend of −1206±277 km2 yr−1 (−1.78±0.41 % yr−1) occurring in the Victoria and Oates Land region in the western Ross Sea. All trends are significant. This new baseline analysis represents a significant advance in our knowledge of the current state of both the global cryosphere and the complex Antarctic coastal system, which are vulnerable to climate variability and change. It will also inform a wide range of other studies.","tags":["Climate Change","Environmetrics","Cryospheric science"],"title":"Eighteen-year record of circum-Antarctic landfast-sea-ice distribution allows detailed baseline characterisation and reveals trends and variability","type":"publication"},{"authors":["Mark S. Handcock","Andrew Hicks","Narayan Sastry","Anne R. Pebley"],"categories":[],"content":"","date":1617235200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1617235200,"objectID":"f9032e19c44e07a2340b9b21942bbfcf","permalink":"https:handcock.github.io/publication/nghbd-note/","publishdate":"2021-04-01T00:00:00Z","relpermalink":"/publication/nghbd-note/","section":"publication","summary":"We revisit a novel causal model published in Demography by Hicks et al. (2018), designed to assess whether exposure to neighborhood disadvantage over time affects children's reading and math skills. Here, we provide corrected and new results. Reconsideration of the model in the original article raised concerns about bias due to exposure-induced confounding (i.e., past exposures directly affecting future exposures) and true state dependence (i.e., past exposures affecting confounders of future exposures). Through simulation, we show that our originally proposed propensity function approach displays modest bias due to exposure-induced confounding but no bias from true state dependence. We suggest a correction based on residualized values and show that this new approach corrects for the observed bias. We contrast this revised method with other causal modeling approaches using simulation. Finally, we reproduce the substantive models from Hicks et al. (2018) using the new residuals-based adjustment procedure. With the correction, our findings are essentially identical to those reported originally. We end with some conclusions regarding approaches to causal modeling.","tags":["Child Development","Neighborhoods","Residential histories","Propensity function models"],"title":"A Note on 'Sequential Neighborhood Effects' by Hicks et al. (2018)","type":"publication"},{"authors":["Marilyn N. Raphael","Mark S. Handcock","Marika M Holland","Laura L Landrum"],"categories":[],"content":"","date":1602892800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602892800,"objectID":"2959f249dd63b676e049b7e9cbae56a0","permalink":"https:handcock.github.io/publication/assess-cesm2/","publishdate":"2020-10-17T00:00:00Z","relpermalink":"/publication/assess-cesm2/","section":"publication","summary":"Understanding the variability of Antarctic sea ice is an ongoing challenge given the limitations of observed data. Coupled climate model simulations present the opportunity to examine this variability in Antarctic sea ice. Here, the daily sea ice extent simulated by the newly released National Center for Atmospheric Research (NCAR) Community Eart h System Model Version 2 (CESM2) for the historical period (1979–2014) is compared to the satellite-observed daily sea ice extent for the same period. The comparisons are made using a newly developed suite of statistical metrics that estimates the variability of the sea ice extent on timescales ranging from the long-term decadal to the short term, intraday scales. Assessed are the annual cycle, trend, day-to-day change, and the volatility, a new statistic that estimates the variability at the daily scale. Results show that the trend in observed daily sea ice is dominated by subdecadal variability with a weak positive linear trend superimposed. The CESM2 simulates comparable subdecadal variability but with a strong negative linear trend superimposed. The CESM2's annual cycle is similar in amplitude to the observed, key differences being the timing of ice advance and retreat. The sea ice begins its advance later, reaches its maximum later and begins retreat later in the CESM2. This is confirmed by the day-to-day change. Apparent in all of the sea ice regions, this behavior suggests the influence of the semiannual oscillation of the circumpolar trough. The volatility, which is associated with smaller scale dynamics such as storms, is smaller in the CESM2 than observed.","tags":["Climate Change","Environmetrics","Cryospheric science"],"title":"An Assessment of the Temporal Variability in the Annual Cycle of Daily Antarctic Sea Ice in the NCAR Community Earth System Model, Version 2: A Comparison of the Historical Runs with Observations","type":"publication"},{"authors":null,"categories":null,"content":"","date":1595548800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595548800,"objectID":"7dc79766d9f3e810b5b5d2606ed32475","permalink":"https:handcock.github.io/project/covid-19/","publishdate":"2020-07-24T00:00:00Z","relpermalink":"/project/covid-19/","section":"project","summary":"Project page for some work on the COVID-19 pandemic.","tags":["Infectious-Diseases"],"title":"COVID-19","type":"project"},{"authors":["Mark S. Handcock","Marilyn N. Raphael"],"categories":[],"content":"","date":1593648e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593648e3,"objectID":"d3ab37bc5834201ea55926c1ee363059","permalink":"https:handcock.github.io/publication/annual-cycle/","publishdate":"2020-07-02T00:00:00Z","relpermalink":"/publication/annual-cycle/","section":"publication","summary":"The total Antarctic sea ice extent (SIE) experiences a distinct annual cycle, peaking in September and reaching its minimum in February. In this paper we propose a mathematical and statistical decomposition of this temporal variation in SIE. Each component is interpretable and, when combined, gives a complete picture of the variation in the sea ice. We consider timescales varying from the instantaneous and not previously defined to the multi-decadal curvilinear trend, the longest. Because our representation is daily, these timescales of variability give precise information about the timing and rates of advance and retreat of the ice and may be used to diagnose physical contributors to variability in the sea ice. We define a number of annual cycles each capturing different components of variation, especially the yearly amplitude and phase that are major contributors to SIE variation. Using daily sea ice concentration data, we show that our proposed invariant annual cycle explains 29 % more of the variation in daily SIE than the traditional method. The proposed annual cycle that incorporates amplitude and phase variation explains 77 % more variation than the traditional method. The variation in phase explains more of the variability in SIE than the amplitude. Using our methodology, we show that the anomalous decay of sea ice in 2016 was associated largely with a change of phase rather than amplitude. We show that the long term trend in Antarctic sea ice extent is strongly curvilinear and the reported positive linear trend is small and dependent strongly on a positive trend that began around 2011 and continued until 2016.","tags":["Climate Change","Environmetrics","Cryospheric science"],"title":"Modeling the annual cycle of daily Antarctic sea ice extent","type":"publication"},{"authors":["Medha Uppala","Mark S. Handcock"],"categories":[],"content":"","date":1583020800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583020800,"objectID":"45bebd2e58ea27f60ee48fd3baff0c92","permalink":"https:handcock.github.io/publication/wildfire/","publishdate":"2020-03-01T00:00:00Z","relpermalink":"/publication/wildfire/","section":"publication","summary":"This paper focuses on spatial and temporal modeling of point processes on linear networks. Point processes on linear networks can simply be defined as point events occurring on or near line segment network structures embedded in a certain space. A separable modeling framework is introduced that posits separate formation and dissolution models of point processes on linear networks over time. While the model was inspired by spider web building activity in brick mortar lines, the focus is on modeling wildfire ignition origins near road networks over a span of 14 years. As most wildfires in California have human-related origins, modeling the origin locations with respect to the road network provides insight into how human, vehicular and structural densities affect ignition occurrence. Model results show that roads that traverse different types of regions such as residential, interface and wildland regions have higher ignition intensities compared to roads that only exist in each of the mentioned region types.","tags":["Point processes","linear network","spatiotemporal modeling","pseudolikelihood","Berman–Turner method","spider webs","wildfires","ignition origins","road networks"],"title":"Modeling wildfire ignition origins in southern California using linear network point processes","type":"publication"},{"authors":["Brian J Kim","Mark S. Handcock"],"categories":[],"content":"","date":1575676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575676800,"objectID":"3cd0830bf2d6cc52eaa551627e4b995e","permalink":"https:handcock.github.io/publication/pse2/","publishdate":"2019-12-07T00:00:00Z","relpermalink":"/publication/pse2/","section":"publication","summary":"Respondent-driven sampling (RDS) is commonly used to study hard-to-reach populations since traditional methods are unable to efficiently survey members due to the typically highly stigmatized nature of the population. The number of people in these populations is of primary global health and demographic interest and is usually hard to estimate. However, due to the nature of RDS, current methods of population size estimation are insufficient. We introduce a new method of estimating population size that uses concepts from capture-recapture methods while modeling RDS as a successive sampling process. We assess its statistical validity using information from the CDC’s National HIV Behavioral Surveillance system in 2009 and 2012.","tags":["Hard-to-reach population sampling","Network sampling","Model-based survey sampling","Capture-recapture","Without replacement sampling"],"title":"Population Size Estimation Using Multiple Respondent-Driven Sampling Surveys","type":"publication"},{"authors":["Alec M. Chan‐Golston","Sudipto Banerjee","Mark S. Handcock"],"categories":[],"content":"","date":1569369600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569369600,"objectID":"315f75c11ab95171f85c8d25aba3a682","permalink":"https:handcock.github.io/publication/bayes-finite-pop/","publishdate":"2019-09-25T00:00:00Z","relpermalink":"/publication/bayes-finite-pop/","section":"publication","summary":"We develop a Bayesian model–based approach to finite population estimation accounting for spatial dependence. Our innovation here is a framework that achieves inference for finite population quantities in spatial process settings. A key distinction from the small area estimation setting is that we analyze finite populations referenced by their geographic coordinates. Specifically, we consider a two-stage sampling design in which the primary units are geographic regions, the secondary units are point-referenced locations, and the measured values are assumed to be a partial realization of a spatial process. Estimation of finite population quantities from geostatistical models does not account for sampling designs, which can impair inferential performance, whereas design-based estimates ignore the spatial dependence in the finite population. We demonstrate by using simulation experiments that process-based finite population sampling models improve model fit and inference over models that fail to account for spatial correlation. Furthermore, the process-based models offer richer inference with spatially interpolated maps over the entire region. We reinforce these improvements and demonstrate scalable inference for groundwater nitrate levels in the population of California Central Valley wells by offering estimates of mean nitrate levels and their spatially interpolated maps.","tags":["Bayesian modeling","finite population inference","hierarchical models","spatial process","two-stagesampling"],"title":"Bayesian inference for finite populations under spatial process settings","type":"publication"},{"authors":["Maryclare Griffin","Elena Erosheva","Krista J. Gile","Mark S. Handcock","Karen Fredriksen-Goldsen"],"categories":[],"content":"","date":1542067200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1542067200,"objectID":"04c35cf57f0b2334324a4508e5b2da42","permalink":"https:handcock.github.io/publication/griffin/","publishdate":"2018-11-13T00:00:00Z","relpermalink":"/publication/griffin/","section":"publication","summary":"Respondent-driven sampling (RDS) is a method for sampling from a target population by leveraging social connections.  RDS is invaluable to the study of hard-to-reach populations.  However, RDS is costly and can be infeasible.  RDS is infeasible when RDS point estimators have small effective sample sizes (large design effects) or when RDS interval estimators have large confidence intervals relative to estimates obtained in previous studies or poor coverage.  As a result, researchers need tools to assess whether or not estimation of certain characteristics of interest for specific populations is feasible in advance.  In this paper, we develop a simulation-based framework for using pilot data—in the form of a convenience sample of aggregated, egocentric data and estimates of subpopulation sizes within the target population—to assess whether or not RDS is feasible for estimating characteristics of a target population.  In doing so, we assume that more is known about egos than alters in the pilot data, which is often the case with aggregated, egocentric data in practice.  We build on existing methods for estimating the structure of social networks from aggregated, egocentric sample data and estimates of subpopulation sizes within the target population.  We apply this framework to assess the feasibility of estimating the proportion male, proportion bisexual, proportion depressed and proportion infected with HIV/AIDS within three spatially distinct target populations of older lesbian, gay and bisexual adults using pilot data from the Caring and Aging with Pride Study and the Gallup Daily Tracking Survey. We conclude that using an RDS sample of 300 subjects is infeasible for estimating the proportion male, but feasible for estimating the proportion bisexual, proportion depressed and proportion infected with HIV/AIDS in all three target populations.","tags":["aggregated egocentric sample data","hard to reach populations","network sampling","Respondent-driven sampling","social networks"],"title":"A Simulation-Based Framework for Assessing the Feasibility of Respondent-Driven Sampling for Estimating Characteristics in Populations of Lesbian, Gay and Bisexual Older Adults","type":"publication"},{"authors":["Sanjay Chaudhuri","Mark S. Handcock"],"categories":[],"content":"","date":1520294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1520294400,"objectID":"af3a25597e23908a453d4bfd28a86984","permalink":"https:handcock.github.io/publication/emplik/","publishdate":"2018-03-06T00:00:00Z","relpermalink":"/publication/emplik/","section":"publication","summary":"We consider an empirical likelihood framework for inference for a statistical model based on an informative sampling design. Covariate information is incorporated both through the weights and the estimating equations. The estimator is based on conditional weights. We show that under usual conditions, with population size increasing unbounded, the estimates are strongly consistent, asymptotically unbiased and normally distributed. Our framework provides additional justification for inverse probability weighted score estimators in terms of conditional empirical likelihood. In doing so, it bridges the gap between design-based and model-based modes of inference in survey sampling settings. We illustrate these ideas with an application to an electoral survey.","tags":["Complex survey data","Design weights","Model parameter estimation","Conditional likelihood","Inverse probability weighted estimation","Design-based survey inference","Generalised linear models"],"title":"A Conditional Empirical Likelihood Based Method for Model Parameter Estimation from Complex survey Datasets","type":"publication"},{"authors":["Krista J. Gile","Isabelle S. Beaudry","Mark S. Handcock","Miles Q. Ott"],"categories":[],"content":"","date":1519862400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1519862400,"objectID":"9371b1fa1b22e43bd685039c8dd11c01","permalink":"https:handcock.github.io/publication/annrevrds/","publishdate":"2018-03-01T00:00:00Z","relpermalink":"/publication/annrevrds/","section":"publication","summary":"Respondent-driven sampling is a commonly used method for sampling from hard-to-reach human populations connected by an underlying social network of relations.  Beginning with a convenience sample, participants pass coupons to invite their contacts to join the sample.  Although the method is often effective at attaining large and varied samples, its reliance on convenience samples, social network contacts, and participant decisions makes it subject to a large number of statistical concerns.  This article reviews inferential methods available for data collected by respondent-driven sampling.","tags":["respondent-driven sampling","link-tracing","not missing at random","network sampling","social network","hard-to-reach population","snowball sampling"],"title":"Methods for Inference from Respondent-Driven Sampling Data","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":1516924800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1516924800,"objectID":"fa28d196df54cc79ad9fb29840175b8f","permalink":"https:handcock.github.io/publication/nonpar-bayes-nets/","publishdate":"2018-01-26T00:00:00Z","relpermalink":"/publication/nonpar-bayes-nets/","section":"publication","summary":"This is an invited discussion of `Nonparametric Bayes Modeling of Populations of Networks` by Daniele Durante, David B. Dunson and Joshua T. Vogelstein.","tags":["network modeling"],"title":"Comment on \"On Nonparametric Bayes Modeling of Populations of Networks\"","type":"publication"},{"authors":["Andrew Hicks","Mark S. Handcock","Narayan Sastry","Anne R. Pebley"],"categories":[],"content":"","date":1512e6,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1512e6,"objectID":"d221e411f68d80bcf55319caf93bf4e5","permalink":"https:handcock.github.io/publication/nghbd/","publishdate":"2017-11-30T00:00:00Z","relpermalink":"/publication/nghbd/","section":"publication","summary":"Prior research has suggested that children living in a disadvantaged neighborhood have lower achievement test scores, but these studies typically have not estimated causal effects that account for neighborhood choice. Recent studies used propensity score methods to account for the endogeneity of neighborhood exposures, comparing disadvantaged and nondisadvantaged neighborhoods. We develop an alternative propensity function approach in which cumulative neighborhood effects are modeled as a continuous treatment variable. This approach offers several advantages. We use our approach to examine the cumulative effects of neighborhood disadvantage on reading and math test scores in Los Angeles. Our substantive results indicate that recency of exposure to disadvantaged neighborhoods may be more important than average exposure for children's test scores. We conclude that studies of child development should consider both average cumulative neighborhood exposure and the timing of this exposure.","tags":["Child Development","Neighborhoods","Residential histories","Propensity function models"],"title":"Sequential Neighborhood Effects: The Effect of Long-Term Exposure to Concentrated Disadvantage on Children's Reading and Mathematical Skills","type":"publication"},{"authors":["Michael W. Spiller","Krista J. Gile","Mark S. Handcock","Corinne M. Mar","Cyprian Wejnert"],"categories":[],"content":"","date":1502928e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1502928e3,"objectID":"ea4c5715aee3cffed3f9eda4e4564987","permalink":"https:handcock.github.io/publication/evalvarrds/","publishdate":"2017-08-17T00:00:00Z","relpermalink":"/publication/evalvarrds/","section":"publication","summary":"Respondent-Driven Sampling (RDS) is a network-based method for sampling hard-to-reach populations that is widely used by public health agencies and researchers worldwide. Estimation of population characteristics from RDS data is challenging due to the unobserved population network, and multiple point and variance estimators have been proposed. Research evaluating these estimators has been limited and largely focused on point estimation; this analysis is the first evaluation of multiple variance estimators currently in use. We evaluated the performance of RDS variance estimators via simulations of RDS on synthetic networked populations constructed from 40 RDS surveys of injection drug users in the United States. In these simulations, average design effects (DEs) were lower and average 95% confidence interval (CI) coverage percentages were higher than suggested in previous work: typical DE range = 1–3; average 95% CI coverage = 93%. However, DE and CI coverage vary across the 40 sets of simulations, suggesting that the characteristics of a given study should be evaluated to assess estimator performance. We also found that simulation results are sensitive to whether sampling is conducted with replacement and the approach used to create CIs. We conclude that CI coverage rates and DEs are often acceptable but not perfect and that RDS estimates are usually reliable in scenarios where RDS assumptions are met. While RDS estimation performed reasonably well, we found strong evidence that the simple random sample variance estimator and corresponding CIs significantly underestimate variance and should not be used to analyze RDS data.","tags":["respondent-driven sampling","link-tracing","not missing at random","network sampling","social network","hard-to-reach population","snowball sampling"],"title":"Evaluating Variance Estimators for Respondent‐Driven Sampling","type":"publication"},{"authors":["Ian E. Fellows","Mark S. Handcock"],"categories":[],"content":"","date":1492646400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1492646400,"objectID":"bb173f030b817245f40d3f7e831c8b7c","permalink":"https:handcock.github.io/publication/phasetapering/","publishdate":"2017-04-20T00:00:00Z","relpermalink":"/publication/phasetapering/","section":"publication","summary":"Gibbs measures are a fundamental class of distributions for the analysis of high dimensional data. Phase transitions, which are also known as degeneracy in the network science literature, are an emergent property of these models that well describe many physical systems.  However, the reach of the Gibbs measure is now far outside the realm of physical systems, and in many of these domains multiphase behavior is a nuisance. This nuisance often makes distribution fitting impossible due to failure of the MCMC sampler, and even when an MLE fit is possible, if the solution is near a phase transition point, the plausibility of the fit can be highly questionable. We introduce a modification to the Gibbs distribution that reduces the effects of phase transitions, and with properly chosen hyper-parameters, provably removes all multiphase behavior. We show that this new distribution is just as easy to fit via MCMCMLE as the Gibbs measure, and provide examples in the Ising model from statistical physics and ERGMs from network science.","tags":["respondent-driven sampling","link-tracing","not missing at random","network sampling","social network","hard-to-reach population","snowball sampling"],"title":"Removing Phase Transitions from Gibbs Measures","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488326400,"objectID":"ecdf5718b5929f22ed27de8b510cb8b4","permalink":"https:handcock.github.io/publication/hansen2015/","publishdate":"2017-03-01T00:00:00Z","relpermalink":"/publication/hansen2015/","section":"publication","summary":"This is an invited discussion of 'Adaptive and Network Sampling for Inference and Interventions in Changing Populations' by Steven K. Thompson, the 2015 Morris Hansen Lecture, November 17, 2015a The Hansen Lecture is jointly sponsored by Washington Statistical Society, WESTAT and NASS.","tags":["network modeling"],"title":"Discussion of \"Adaptive and Network Sampling for Inference and Interventions in Changing Populations\" by Steven K. Thompson","type":"publication"},{"authors":["Jane Carlen","Mark S. Handcock"],"categories":[],"content":"","date":1488326400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1488326400,"objectID":"becd00d55a6905d094cf02206621b3ec","permalink":"https:handcock.github.io/publication/citation2016/","publishdate":"2017-03-01T00:00:00Z","relpermalink":"/publication/citation2016/","section":"publication","summary":"This is a discussion of 'Statistical Modelling of Citation Exchange Between Statistics Journals' by Cristiano Varin, Manuela Cattelan and David Firth, read before The Royal Statistical Society at a meeting organized by the General Applications Section on Wednesday, May 13th, 2015, Professor P. Clarke in the Chair","tags":["network modeling"],"title":"Discussion of \"Statistical Modelling of Citation Exchange Between Statistics Journals” by Cristiano Varin, Manuela Cattelan and David Firth","type":"publication"},{"authors":["Ryan Admiraal","Mark S. Handcock"],"categories":[],"content":"","date":1480550400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1480550400,"objectID":"e69b5dc588f2db5992b48234f74175e0","permalink":"https:handcock.github.io/publication/concurrency/","publishdate":"2016-12-01T00:00:00Z","relpermalink":"/publication/concurrency/","section":"publication","summary":"Network-based models for sexually transmitted disease transmission rely on initial partnership networks incorporating structures that may be related to risk of infection. In particular, initial networks should reflect the level of concurrency and attribute-based selective mixing observed in the population of interest. We consider momentary degree distributions as measures of concurrency and propensities for people of certain types to form partnerships with each other as a measure of attribute-based selective mixing. Estimation of momentary degree distributions and mixing patterns typically relies on cross-sectional survey data, and, in the context of heterosexual networks, we describe how this results in two sets of reports that need not be consistent with each other. The reported momentary degree distributions and mixing totals are related through a series of constraints, however. We provide a method to incorporate those in jointly estimating momentary degree distributions and mixing totals. We develop a method to simulate heterosexual networks consistent with these momentary degree distributions and mixing totals, applying it to data obtained from the National Longitudinal Study of Adolescent Health. We first use the momentary degree distributions and mixing totals as mean value parameters to estimate the natural parameters for an exponential-family random graph model and then use a Markov chain Monte Carlo algorithm to simulate person-level heterosexual partnership networks.","tags":["constrained maximum likelihood estimation","exponential-family random graph models","Heterosexual partnership networks","National Longitudinal Survey of Adolescent Health"],"title":"Modeling Concurrency and Selective Mixing in Heterosexual Partnership Networks with Applications to Sexually Transmitted Diseases","type":"publication"},{"authors":["Krista J. Gile","Mark S. Handcock"],"categories":[],"content":"","date":1475107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1475107200,"objectID":"ced95521a4c9f52fd25d539e843a7eea","permalink":"https:handcock.github.io/publication/netmiss/","publishdate":"2016-09-29T00:00:00Z","relpermalink":"/publication/netmiss/","section":"publication","summary":"It is common in the analysis of social network data to assume a census of the networked population of interest.  Often the observations are subject to partial observation due to a known sampling or unknown missing data mechanism.  However, most social network analysis ignores the problem of missing data by including only actors with complete observations.  We address the modelling of networks with missing data, developing previous ideas in missing data, network modelling and network sampling.  We use several methods including the mean value parameterization to show the quantitative and substantive differences between naive and principled modelling approaches.  We also develop goodness-of-fit techniques to understand model fit better.  The ideas are motivated by an analysis of a friendship network from the National Longitudinal Study of Adolescent Health.","tags":["AddHealth","exponential random graph model","maximum likelihood estimation","nonresponse","sample survey","statnet"],"title":"Analysis of Networks with Missing Data with Application to the National Longitudinal Study of Adolescent Health","type":"publication"},{"authors":["Paul Wesson","Mark S. Handcock","Willi McFarland","H. Fisher Raymond"],"categories":[],"content":"","date":1442793600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1442793600,"objectID":"38a55ab7fad53612a2de85fbad5cf3c1","permalink":"https:handcock.github.io/publication/wesson2015/","publishdate":"2015-09-21T00:00:00Z","relpermalink":"/publication/wesson2015/","section":"publication","summary":"African-American men who have sex with men (AA MSM) have been disproportionately infected with and affected by HIV and other STIs in San Francisco and the USA. The true scope and scale of the HIV epidemic in this population has not been quantified, in part because the size of this population remains unknown. We used the successive sampling population size estimation (SS-PSE) method, a new Bayesian approach to population size estimation that incorporates network size data routinely collected in respondent-driven sampling (RDS) studies, to estimate the number of AA MSM in San Francisco. This method was applied to data from a 2009 RDS study of AA MSM. An estimate from a separate study of local AA MSM was used to model the prior distribution of the population size. Two-hundred and fifty-six AA MSM were included in the RDS survey. The estimated population size was 4917 (95% CI 1267–28,771), using a flat prior estimated 1882 (95% CI 919–2463) as a lower acceptable bound, and a large prior estimated 6762 (95% CI 1994–13,863) as an acceptable upper bound. Point estimates from the SS-PSE were consistent with estimates from multiplier methods using external data. The SS-PSE method is easily integrated into RDS studies and therefore provides a simple and appealing tool to rapidly produce estimates of the size of key populations otherwise difficult to reach and enumerate.","tags":["Population size estimation","African-American","Men who have sex with men","HIV/AIDS","Respondent-driven sampling"],"title":"If You Are Not Counted, You Don’t Count: Estimating the Number of African-American Men Who Have Sex with Men in San Francisco Using a Novel Bayesian Approach","type":"publication"},{"authors":["Michael Schweinberger","Mark S. Handcock"],"categories":[],"content":"","date":1433116800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1433116800,"objectID":"f7983a216f868cfd0df6dd67d862e45d","permalink":"https:handcock.github.io/publication/localdep15/","publishdate":"2015-06-01T00:00:00Z","relpermalink":"/publication/localdep15/","section":"publication","summary":"Dependent phenomena, such as relational, spatial and temporal phenomena, tend to be characterized by local dependence in the sense that units which are close in a well-defined sense are dependent. In contrast with spatial and temporal phenomena, though, relational phenomena tend to lack a natural neighbourhood structure in the sense that it is unknown which units are close and thus dependent. Owing to the challenge of characterizing local dependence and constructing random graph models with local dependence, many conventional exponential family random graph models induce strong dependence and are not amenable to statistical inference. We take first steps to characterize local dependence in random graph models, inspired by the notion of finite neighbourhoods in spatial statistics and M-dependence in time series, and we show that local dependence endows random graph models with desirable properties which make them amenable to statistical inference. We show that random graph models with local dependence satisfy a natural domain consistency condition which every model should satisfy, but conventional exponential family random graph models do not satisfy. In addition, we establish a central limit theorem for random graph models with local dependence, which suggests that random graph models with local dependence are amenable to statistical inference. We discuss how random graph models with local dependence can be constructed by exploiting either observed or unobserved neighbourhood structure. In the absence of observed neighbourhood structure, we take a Bayesian view and express the uncertainty about the neighbourhood structure by specifying a prior on a set of suitable neighbourhood structures. We present simulation results and applications to two real world networks with ‘ground truth’.","tags":["Exponential families","Local dependence;M-dependence","Model degeneracy","Social networks","Weak dependence"],"title":"Local Dependence in Random Graph Models: Characterisation, Properties, and Statistical Inference","type":"publication"},{"authors":["Ryan Admiraal","Mark S. Handcock"],"categories":[],"content":"","date":1422748800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1422748800,"objectID":"746c289c838a8ac25df371e79d2b2f12","permalink":"https:handcock.github.io/publication/ego-reports/","publishdate":"2015-02-01T00:00:00Z","relpermalink":"/publication/ego-reports/","section":"publication","summary":"We propose a log-linear model to assess the consistency of ego reports of dyadic outcomes. We do so specifically in the context where males and females report on shared events, and we demonstrate how inconsistencies can be assessed by using a log-linear model that estimates separate mixing totals for each set of reports. This modelling approach immediately allows us to determine where inconsistencies in reports occur. To demonstrate how our method can be easily implemented for survey data, we apply it to both the 1992 National Health and Social Life Survey and the 2002 National Survey of Family Growth. Our analysis identifies inconsistencies in male and female reports of concurrent partnerships and the number of biological children.","tags":["Bipartite networks","Demography","Egocentric data","Social network models","Survey sampling"],"title":"A Loglinear Modeling Approach to Assessing the Consistency of Ego Reports of Dyadic Outcomes with Applications to Fertility and Sexual Partnerships","type":"publication"},{"authors":["Krista J. Gile","Mark S. Handcock"],"categories":[],"content":"","date":1422316800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1422316800,"objectID":"6501cc7ec0df65faa4e4f6ec3a2b2589","permalink":"https:handcock.github.io/publication/model-assist15/","publishdate":"2015-01-27T00:00:00Z","relpermalink":"/publication/model-assist15/","section":"publication","summary":"Respondent-driven sampling is a widely used method for sampling hard-to-reach human populations by link tracing over their social networks. Inference from such data requires specialized techniques because the sampling process is both partially beyond the control of the researcher, and partially implicitly defined. Therefore, it is not generally possible to compute the sampling weights for traditional design-based inference directly, and likelihood inference requires modelling the complex sampling process. As an alternative, we introduce a model-assisted approach, resulting in a design-based estimator leveraging a working network model. We derive a new class of estimators for population means and a corresponding bootstrap standard error estimator. We demonstrate improved performance compared with existing estimators, including adjustment for an initial convenience sample. We also apply the method and an extension to the estimation of the prevalence of human immunodeficiency virus in a high-risk population.","tags":["Exponential-family random graph model","Hard-to-reach population sampling","Link-tracing","Network sampling","Social networks"],"title":"Network Model-Assisted Inference from Respondent-Driven Sampling Data","type":"publication"},{"authors":["Mark S. Handcock","Krista J. Gile","Corinne M. Mar"],"categories":[],"content":"","date":1421107200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1421107200,"objectID":"224c4bb61589e87c180b8526587e8ef4","permalink":"https:handcock.github.io/publication/psebiometrics/","publishdate":"2015-01-13T00:00:00Z","relpermalink":"/publication/psebiometrics/","section":"publication","summary":"The study of hard-to-reach populations presents significant challenges. Typically, a sampling frame is not available, and population members are difficult to identify or recruit from broader sampling frames. This is especially true of populations at high risk for HIV/AIDS. Respondent-driven sampling (RDS) is often used in such settings with the primary goal of estimating the prevalence of infection. In such populations, the number of people at risk for infection and the number of people infected are of fundamental importance. This article presents a case-study of the estimation of the size of the hard-to-reach population based on data collected through RDS. We study two populations of female sex workers and men-who-have-sex-with-men in El Salvador. The approach is Bayesian and we consider different forms of prior information, including using the UNAIDS population size guidelines for this region. We show that the method is able to quantify the amount of information on population size available in RDS samples. As separate validation, we compare our results to those estimated by extrapolating from a capture–recapture study of El Salvadorian cities. The results of our case-study are largely comparable to those of the capture–recapture study when they differ from the UNAIDS guidelines. Our method is widely applicable to data from RDS studies and we provide a software package to facilitate this.","tags":["Hard-to-reach population sampling","model-based survey sampling","network sampling","social networks","successive sampling"],"title":"Estimating the Size of Populations at High Risk for HIV using Respondent-Driven Sampling Data","type":"publication"},{"authors":["Lisa G. Johnston","Katherine R. McLaughlin","Houssine El Rhilani","Amina Latifi","Abdalla Toufik","Aziza Bennani","Kamal Alami","Boutaina Elomari","Mark S. Handcock"],"categories":[],"content":"","date":1420675200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1420675200,"objectID":"d2fe171dce10b7c56465ac7dbe48d3ed","permalink":"https:handcock.github.io/publication/morocco2015/","publishdate":"2015-01-08T00:00:00Z","relpermalink":"/publication/morocco2015/","section":"publication","summary":"Background: Respondent-driven sampling is used worldwide to estimate the population prevalence of characteristics, such as HiV/aiDS and associated risk factors in hard-to-reach populations. estimating the total size of these populations is of great interest to national and international organizations; however, reliable measures of population size often do not exist. Methods: Successive sampling-population size estimation (SS-PSe) along with network size imputation allows population size estimates to be made without relying on separate studies or additional data (as in network scale-up, multiplier, and capture–recapture methods), which may be biased. Results: ten population size estimates were calculated for people who inject drugs, female sex workers, men who have sex with other men, and migrants from sub-Saharan africa in six different cities in Morocco. SS-PSe estimates fell within or very close to the likely values provided by experts and the estimates from previous studies using other methods. Conclusions: SS-PSe is an effective method for estimating the size of hard-to-reach populations that leverages important information within respondent-driven sampling studies. the addition of a network size imputation method helps to smooth network sizes allowing for more accurate results. However, caution should be used particularly when there is reason to believe that clustered subgroups may exist within the population of interest or when the sample size is small in relation to the population.","tags":["Population size estimation","African-American","Men who have sex with men","HIV/AIDS","Respondent-driven sampling"],"title":"Estimating the size of hidden populations using respondent-driven sampling data: Case examples from Morocco","type":"publication"},{"authors":["Mark S. Handcock","Krista J. Gile","Corinne M. Mar"],"categories":[],"content":"","date":1409616e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1409616e3,"objectID":"59b4587485e4d3549b0054412740fc66","permalink":"https:handcock.github.io/publication/pseej/","publishdate":"2014-09-02T00:00:00Z","relpermalink":"/publication/pseej/","section":"publication","summary":"Respondent-Driven Sampling (RDS) is n approach to sampling design and inference in hard-to-reach human populations. It is often used in situations where the target population is rare and/or stigmatized in the larger population, so that it is prohibitively expensive to contact them through the available frames. Common examples include injecting drug users, men who have sex with men, and female sex workers. Most analysis of RDS data has focused on estimating aggregate characteristics, such as disease prevalence. However, RDS is often conducted in settings where the population size is unknown and of great independent interest. This paper presents an approach to estimating the size of a target population based on data collected through RDS. The proposed approach uses a successive sampling approximation to RDS to leverage information in the ordered sequence of observed personal network sizes. The inference uses the Bayesian framework, allowing for the incorporation of prior knowledge. A ﬂexible class of priors for the population size is used that aids elicitation. An extensive simulation study provides insight into the performance of the method for estimating population size under a broad range of conditions. A further study shows the approach also improves estimation of aggregate characteristics. Finally, the method demonstrates sensible results when used to estimate the size of known networked populations from the National Longitudinal Study of Adolescent Health, and when used to estimate the size of a hard-to-reach population at high risk for HIV.","tags":["Hard-to-reach population sampling","model-based survey sampling","network sampling","social networks","successive sampling"],"title":"Estimating Hidden Population Size using Respondent-Driven Sampling Data","type":"publication"},{"authors":["Jocelyn T. Chi","Mark S. Handcock"],"categories":[],"content":"","date":1405123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1405123200,"objectID":"f70118a18212dd07ca0fe171c4b0bdb1","permalink":"https:handcock.github.io/publication/jocelymchi/","publishdate":"2014-07-12T00:00:00Z","relpermalink":"/publication/jocelymchi/","section":"publication","summary":"Many studies show that immigrants face significant barriers in accessing health care. These barriers may be particularly pronounced for newer immigrants, who may face additional obstacles in navigating the health care system. Understanding the sources of health care disparities between recent and non-recent immigrants may allow for better design of policies and interventions to address the vulnerabilities unique to different subgroups of immigrants defined by their length of residency. This study employs descriptive analyses and multivariate logistic regression to estimate the likelihood of accessing and utilizing health care services based on immigration-related factors after controlling for predisposing, enabling, and health care need factors. We also employ a regression-based decomposition method to determine whether health care differences between recent and non-recent immigrants are statistically significant and to identify the primary drivers of healthcare differences between recent and non-recent immigrants. The findings support the hypothesis that significant disparities in health care access and utilization exist between recent and non-recent immigrants. We found that health care access and utilization differences between recent and non-recent immigrants were driven primarily by enabling resources, including limited English proficiency (LEP), insurance status, public assistance usage, and poverty level. These results indicate that not only are newer immigrants more likely to underutilize health care, but also that their underutilization is driven primarily by their lack of insurance, lack of adequate financial resources, and inability to navigate the health care system due to LEP. The results further indicate that immigrants with prolonged LEP may be less likely to have a usual source of care and more likely to report delays in obtaining medical treatments, than even recent immigrants with LEP.","tags":["Immigration","Recent immigrants","Health care access","Health care utilization","Health care disparities","Health care barriers"],"title":"Identifying Sources of Health Care Underutilization among California's Immigrants","type":"publication"},{"authors":["Pavel N. Krivitsky","Mark S. Handcock"],"categories":[],"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"11a1a1e34c39837ecc51dd590be4729f","permalink":"https:handcock.github.io/publication/separable/","publishdate":"2014-01-01T00:00:00Z","relpermalink":"/publication/separable/","section":"publication","summary":"Models of dynamic networks—networks that evolve over time—have manifold applications. We develop a discrete time generative model for social network evolution that inherits the richness and flexibility of the class of exponential family random-graph models. The model—a separable temporal exponential family random-graph model—facilitates separable modelling of the tie duration distributions and the structural dynamics of tie formation. We develop likelihood-based inference for the model and provide computational algorithms for maximum likelihood estimation. We illustrate the interpretability of the model in analysing a longitudinal network of friendship ties within a school.","tags":["Social networks","Longitudinal","Exponential-family random graph model","Markov chain Monte Carlo","Maximum likelihood estimation"],"title":"A Separable Model for Dynamic Networks","type":"publication"},{"authors":["Alicia Carriquiry and Malay Majmundar, Editors","Panel on Survey Options for Estimating the Flow of Unauthorized Crossings at the U.S.-Mexico Border, including Mark S. Handcock"],"categories":[],"content":"","date":1370044800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1370044800,"objectID":"18854be9f51895006d331838a34e1935","permalink":"https:handcock.github.io/publication/nas-immigration/","publishdate":"2013-06-01T00:00:00Z","relpermalink":"/publication/nas-immigration/","section":"publication","summary":"This is the report of the Panel on Survey Options for Estimating the Flow of Unauthorized Crossings at the U.S.-Mexico Border, including myself as a panel member. The summary is below: The U.S. Department of Homeland Security (DHS) is responsible for securing and managing the nation's borders. Over the past decade, DHS has dramatically stepped up its enforcement efforts at the U.S.-Mexico border, increasing the number of U.S. Border patrol (USBP) agents, expanding the deployment of technological assets, and implementing a variety of 'consequence programs' intended to deter illegal immigration. During this same period, there has also been a sharp decline in the number of unauthorized migrants apprehended at the border. Trends in total apprehensions do not, however, by themselves speak to the effectiveness of DHS's investments in immigration enforcement. In particular, to evaluate whether heightened enforcement efforts have contributed to reducing the flow of undocumented migrants, it is critical to estimate the number of border-crossing attempts during the same period for which apprehensions data are available. With these issues in mind, DHS charged the National Research Council (NRC) with providing guidance on the use of surveys and other methodologies to estimate the number of unauthorized crossings at the U.S.-Mexico border, preferably by geographic region and on a quarterly basis. Options for Estimating Illegal Entries at the U.S.-Mexico Border focuses on Mexican migrants since Mexican nationals account for the vast majority (around 90 percent) of attempted unauthorized border crossings across the U.S.-Mexico border.","tags":["survey sampling"],"title":"Estimating Illegal Entries at the U.S.-Mexico Border","type":"publication"},{"authors":["David R. Hunter","Steven M. Goodreau","Mark S. Handcock"],"categories":[],"content":"","date":1359676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1359676800,"objectID":"1d3026d128aa7699139992ff35a4c1d1","permalink":"https:handcock.github.io/publication/ergm.userterms/","publishdate":"2013-02-01T00:00:00Z","relpermalink":"/publication/ergm.userterms/","section":"publication","summary":"Exponential-family random graph models (ERGMs) represent a powerful and flexible class of models for the statistical analysis of networks. statnet is a suite of software packages that implement these models. This paper details how the capabilities for ERGM modeling can be expanded and customized by programming additional network statistics that may be included in ERGMs. We describe a template R package called ergm.userterms that can be modified for this purpose. It is designed to make this process as straightforward as possible. We also explain some of the internal workings of statnet that will help users develop their own network analysis capabilities.","tags":["exponential-family random graph model","Markov chain Monte Carlo","maximum likelihood estimation","p-star model"],"title":"ergm.userterms: A Template Package for Extending statnet","type":"publication"},{"authors":["Gail E. Potter","Mark S. Handcock","Ira M. Longini Jr.","M. Elizabeth Halloran"],"categories":[],"content":"","date":1330992e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1330992e3,"objectID":"13fe31e088be973a395e19b188d90056","permalink":"https:handcock.github.io/publication/within-school/","publishdate":"2012-03-06T00:00:00Z","relpermalink":"/publication/within-school/","section":"publication","summary":"Many epidemic models approximate social contact behavior by assuming random mixing within mixing groups (e.g., homes, schools and workplaces). The effect of more realistic social network structure on estimates of epidemic parameters is an open area of exploration. We develop a detailed statistical model to estimate the social contact network within a high school using friendship network data and a survey of contact behavior. Our contact network model includes classroom structure, longer durations of contacts to friends than nonfriends and more frequent contacts with friends, based on reports in the contact survey. We performed simulation studies to explore which network structures are relevant to influenza transmission. These studies yield two key findings. First, we found that the friendship network structure important to the transmission process can be adequately represented by a dyad-independent exponential random graph model (ERGM). This means that individual-level sampled data is sufficient to characterize the entire friendship network. Second, we found that contact behavior was adequately represented by a static rather than dynamic contact network. We then compare a targeted antiviral prophylaxis intervention strategy and a grade closure intervention strategy under random mixing and network-based mixing. We find that random mixing overestimates the effect of targeted antiviral prophylaxis on the probability of an epidemic when the probability of transmission in 10 minutes of contact is less than 0.004 and underestimates it when this transmission probability is greater than 0.004. We found the same pattern for the final size of an epidemic, with a threshold transmission probability of 0.005. We also find random mixing overestimates the effect of a grade closure intervention on the probability of an epidemic and final size for all transmission probabilities. Our findings have implications for policy recommendations based on models assuming random mixing, and can inform further development of network-based models.","tags":["Contact network","epidemic model","inﬂuenza","simulation model","social network"],"title":"Estimating Within-School Contact Networks To Understand Influenza Transmission","type":"publication"},{"authors":["Ruth M. Hummel","David R. Hunter","Mark S. Handcock"],"categories":[],"content":"","date":1330992e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1330992e3,"objectID":"5a8868e20562c5ec3b593eab6004bbca","permalink":"https:handcock.github.io/publication/improved-sim/","publishdate":"2012-03-06T00:00:00Z","relpermalink":"/publication/improved-sim/","section":"publication","summary":"Markov chain Monte Carlo methods can be used to approximate the intractable normalizing constants that arise in likelihood calculations for many exponential-family random graph models for networks. However, in practice, the resulting approximations degrade as parameter values move away from the value used to define the Markov chain, even in cases where the chain produces perfectly efficient samples. We introduce a new approximation method along with a novel method of moving toward a maximum likelihood estimator (MLE) from an arbitrary starting parameter value in a series of steps based on alternating between the canonical exponential-family parameterization and the mean-value parameterization. This technique enables us to find an approximate MLE in many cases where this was previously not possible. We illustrate these methods on a model for a transcriptional regulation network for E. coli, an example where previous attempts to approximate an MLE had failed, and a model for a well-known social network dataset involving friendships among workers in a tailor shop. These methods are implemented in the publicly available ergm package for R, and computer code to duplicate the results of this article is included in the online supplementary materials.","tags":["Exponential-family random graph model","Markov chain Monte Carlo","Maximum likelihood estimation","Mean value parameterization"],"title":"Improving simulation-based algorithms for fitting ERGMs","type":"publication"},{"authors":["Mark S. Handcock","Krista J. Gile"],"categories":[],"content":"","date":1318982400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1318982400,"objectID":"141e37453b969dcd6903bfb0554feb87","permalink":"https:handcock.github.io/publication/onsnowball/","publishdate":"2011-10-19T00:00:00Z","relpermalink":"/publication/onsnowball/","section":"publication","summary":"A phenomenon in the sociology of science is that multidisciplinary fields tend to produce a plethora of inconsistent terminology.  Often the meaning of a term evolves over time, or different terms are used for the same concept.  More confusing is the use of the same term for different concepts. The term 'snowball sampling' suffers from this treatment.  It has likely been in informal use for a long time, but it certainly predates Coleman (1958) and Trow (1957).  The earliest systematic work dates to the 1940s from the Columbia Bureau of Applied Social Research, led by Paul Lazarsfeld.  In this note we review the history of the term 'snowball sampling'.","tags":["respondent-driven sampling","link-tracing","not missing at random","network sampling","social network","hard-to-reach population","snowball sampling"],"title":"On the Concept of Snowball Sampling","type":"publication"},{"authors":["Gail E. Potter","Mark S. Handcock","Ira M. Longini Jr.","M. Elizabeth Halloran"],"categories":[],"content":"","date":1318464e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1318464e3,"objectID":"474d59c38fa77a5ffeeb92b00c8032c0","permalink":"https:handcock.github.io/publication/within-household/","publishdate":"2011-10-13T00:00:00Z","relpermalink":"/publication/within-household/","section":"publication","summary":"Acute respiratory diseases are transmitted over networks of social contacts. Large-scale simulation models are used to predict epidemic dynamics and evaluate the impact of various interventions, but the contact behavior in these models is based on simplistic and strong assumptions which are not informed by survey data. These assumptions are also used for estimating transmission measures such as the basic reproductive number and secondary attack rates. Development of methodology to infer contact networks from survey data could improve these models and estimation methods. We contribute to this area by developing a model of within-household social contacts and using it to analyze the Belgian POLYMOD data set, which contains detailed diaries of social contacts in a 24-hour period. We model dependency in contact behavior through a latent variable indicating which household members are at home. We estimate age-specific probabilities of being at home and age-specific probabilities of contact conditional on two members being at home. Our results differ from the standard random mixing assumption. In addition, we find that the probability that all members contact each other on a given day is fairly low: 0.49 for households with two 0–5 year olds and two 19–35 year olds, and 0.36 for households with two 12–18 year olds and two 36+ year olds. We find higher contact rates in households with 2–3 members, helping explain the higher influenza secondary attack rates found in households of this size.","tags":["Contact network","epidemic model","graphs","latent variable","social networks"],"title":"Estimating Within-Household Contact Networks from Egocentric Data","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":1312243200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1312243200,"objectID":"32969767f6d2e5b02d826548b7644536","permalink":"https:handcock.github.io/publication/survey-calibration/","publishdate":"2011-08-02T00:00:00Z","relpermalink":"/publication/survey-calibration/","section":"publication","summary":"This is an invited discussion of 'Connections between survey calibration estimators and semi parametric models for incomplete data' by Thomas Lumley, Pamela A. Shaw and James Y. Dai.","tags":["survey sampling"],"title":"Discussion of 'Connections between survey calibration estimators and semi parametric models for incomplete data' by Thomas Lumley, Pamela A. Shaw and James Y. Dai","type":"publication"},{"authors":["Pavel N. Krivitsky","Mark S. Handcock","Martina Morris"],"categories":[],"content":"","date":1309478400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1309478400,"objectID":"63a611aa5e2b11345669974e22fb9d9f","permalink":"https:handcock.github.io/publication/network-size/","publishdate":"2011-07-01T00:00:00Z","relpermalink":"/publication/network-size/","section":"publication","summary":"Exponential-family random graph models (ERGMs) provide a principled way to model and simulate features common in human social networks, such as propensities for homophily and friend-of-a-friend triad closure. We show that, without adjustment, ERGMs preserve density as network size increases. Density invariance is often not appropriate for social networks. We suggest a simple modification based on an offset which instead preserves the mean degree and accommodates changes in network composition asymptotically. We demonstrate that this approach allows ERGMs to be applied to the important situation of egocentrically sampled data. We analyze data from the National Health and Social Life Survey (NHSLS).","tags":["Contact network","epidemic model","inﬂuenza","simulation model","social network"],"title":"Adjusting for network size and composition effects in exponential-family random graph models","type":"publication"},{"authors":["Gail E. Potter","Mark S. Handcock"],"categories":[],"content":"","date":1279584e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1279584e3,"objectID":"889e5c12f093fde9f5c9f05e7e9160e6","permalink":"https:handcock.github.io/publication/malawian/","publishdate":"2010-07-20T00:00:00Z","relpermalink":"/publication/malawian/","section":"publication","summary":"In this paper we explore patterns of economic transfers between adults within household and family networks in a village in Malawi’s Rumphi district, using data from the 2006 round of the Malawi Longitudinal Study of Families and Health. We fit Exponential-family Random Graph Models (ERGMs) to assess individual, relational, and higher-order network effects. The network effects of cyclic giving, reciprocity, and in-degree and out-degree distribution suggest a network with a tendency away from the formation of hierarchies or 'hubs.' Effects of age, sex, working status, education, health status, and kinship relation are also considered.","tags":["Contact network","epidemic model","inﬂuenza","simulation model","social network"],"title":"A Description of Within-family Resource Exchange Networks in a Malawian Village","type":"publication"},{"authors":["Krista J. Gile","Mark S. Handcock"],"categories":[],"content":"","date":1277683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1277683200,"objectID":"e9f3c44236e3988d98ba1ca8becbbfd4","permalink":"https:handcock.github.io/publication/assess-rds/","publishdate":"2010-06-28T00:00:00Z","relpermalink":"/publication/assess-rds/","section":"publication","summary":"Respondent-driven sampling (RDS) employs a variant of a link-tracing network sampling strategy to collect data from hard-to-reach populations. By tracing the links in the underlying social network, the process exploits the social structure to expand the sample and reduce its dependence on the initial (convenience) sample. The current estimators of population averages make strong assumptions in order to treat the data as a probability sample. We evaluate three critical sensitivities of the estimators: (1) to bias induced by the initial sample, (2) to uncontrollable features of respondent behavior, and (3) to the without-replacement structure of sampling. Our analysis indicates: (1) that the convenience sample of seeds can induce bias, and the number of sample waves typically used in RDS is likely insufficient for the type of nodal mixing required to obtain the reputed asymptotic unbiasedness; (2) that preferential referral behavior by respondents leads to bias; (3) that when a substantial fraction of the target population is sampled the current estimators can have substantial bias. This paper sounds a cautionary note for the users of RDS. While current RDS methodology is powerful and clever, the favorable statistical properties claimed for the current estimates are shown to be heavily dependent on often unrealistic assumptions. We recommend ways to improve the methodology.","tags":["Hard-to-reach population sampling","survey sampling","network sampling","social networks","successive sampling"],"title":"Respondent-Driven Sampling: An Assessment of Current Methodology","type":"publication"},{"authors":["Adam Glynn","Thomas S. Richardson","Mark S. Handcock"],"categories":[],"content":"","date":1267401600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1267401600,"objectID":"98751204938ddddc29e19c12151bbd23","permalink":"https:handcock.github.io/publication/contested-elections/","publishdate":"2010-03-01T00:00:00Z","relpermalink":"/publication/contested-elections/","section":"publication","summary":"In close elections, the losing side has an incentive to obtain evidence that the election result is incorrect. Sometimes this evidence comes in the form of court testimony from a sample of invalid voters, and this testimony is used to adjust vote totals (Belcher v. Mayor of Ann Arbor 1978; Borders v. King County 2005). However, while courts may be reluctant to make explicit findings about out-of-sample data (e.g., invalid voters that do not testify), when samples are used to adjust vote totals, the court is making such findings implicitly. In this paper, we show that the practice of adjusting vote totals on the basis of potentially unrepresentative samples can lead to incorrectly voided election results. More generally, we demonstrate that even when frame error and measurement error are minimal, random samples of post-vote vote-choice data can have limited power to detect incorrect election results without high response rates, precinct level polarization, or the acceptance of large Type I error rates. Therefore, in U.S. election disputes, even high-quality post-vote vote-choice data may be insufficient to resolve contested elections without the use of modeling assumptions (whether or not these assumptions are acknowledged).","tags":["Election challenge","Nonresponse","Power analysis"],"title":"Resolving Contested Elections: The Limited Power of Post-Vote Vote Choice Data","type":"publication"},{"authors":["Michael S. Rendall","Mark S. Handcock","Stefan H. Jonsson"],"categories":[],"content":"","date":1233446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1233446400,"objectID":"dd1e478165ec7b72cae1479bd8a50068","permalink":"https:handcock.github.io/publication/bayesdemo/","publishdate":"2009-02-01T00:00:00Z","relpermalink":"/publication/bayesdemo/","section":"publication","summary":"Previous studies have demonstrated both large gains in efficiency and reductions in bias by incorporating population information in regression estimation with sample survey data. These studies, however, assumed that the population values are exact. This assumption is relaxed here through a Bayesian extension of constrained maximum likelihood estimation applied to U.S. Hispanic fertility. The Bayesian approach allows for the use of both auxiliary survey data and expert judgment in making adjustments to published Hispanic Population fertility rates, and for the estimation of uncertainty about these adjustments. Compared with estimation from sample survey data only, the Bayesian constrained estimator results in much greater precision in the age pattern of the baseline fertility hazard and therefore of the predicted values for any given combination of socioeconomic variables. The use of population data in combination with survey data may therefore be highly advantageous even when the population data are known to have significant levels of nonsampling error.","tags":["Hispanic Woman","Bayesian Estimation","Mean Square Deviation","Constraint Model","Unconstrained Model"],"title":"Bayesian estimation of hispanic fertility hazards from survey and population data","type":"publication"},{"authors":["David Krackhardt","Mark S. Handcock"],"categories":[],"content":"","date":1170288e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1170288e3,"objectID":"a540fc860374de4a10445488d4cc4d13","permalink":"https:handcock.github.io/publication/heidersimmel2008/","publishdate":"2007-02-01T00:00:00Z","relpermalink":"/publication/heidersimmel2008/","section":"publication","summary":"This is a paper as part of the reviewed proceedings of the ICML 2006 Workshop on Statistical Network Analysis, entitled 'Statistical Network Analysis: Models, Issues, and New Directions' published in the Lecture Notes in Computer Science Series. Heider’s balance theory is ubiquitous in the field of social networks as an explanation for why we so frequently observe symmetry and transitivity in social relations. We propose that Simmelian tie theory could explain the same phenomena without resorting to motivational tautologies that characterize psychological explanations. Further, while both theories predict the same equilibrium state, we argue that they suggest different processes by which this equilibrium is reached. We develop a dynamic exponential random graph model (ERGM) and apply it to the classic panel data collected by Newcomb to empirically explore these two theories. We find strong evidence that Simmelian triads exist and are stable beyond what would be expected through Heiderian tendencies in the data.","tags":["network modeling"],"title":"Heider vs Simmel: Emergent Features in Dynamic Structures","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":1170288e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1170288e3,"objectID":"ccf86499936e5627c88bd40289bcc158","permalink":"https:handcock.github.io/publication/icml062007disc/","publishdate":"2007-02-01T00:00:00Z","relpermalink":"/publication/icml062007disc/","section":"publication","summary":"This is a discussion of the ICML 2006 Workshop on Statistical Network Analysis, entitled 'Statistical Network Analysis: Models, Issues, and New Directions' published in the Lecture Notes in Computer Science Series.","tags":["network modeling"],"title":"Statistical Network Analysis: Models, Issues and New Directions: Panel Discussion","type":"publication"},{"authors":["Krista J. Gile","Mark S. Handcock"],"categories":[],"content":"","date":1157587200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1157587200,"objectID":"dc9d18bed203660cf5500e600006e39a","permalink":"https:handcock.github.io/publication/cssswp_66/","publishdate":"2006-09-07T00:00:00Z","relpermalink":"/publication/cssswp_66/","section":"publication","summary":"Most inference using social network models assumes that the presence or absence of all relations is known. This is rarely the case. Most social network analysis ignores the problem of missing data by including only actors with complete observations. In this paper we use a statistical model for the underlying social network to demonstrate that the computationally parsimonious complete case approach can lead to different conclusions from an approach utilizing all observations. We also show that the overall fit to the data is improved by extending the model to represent differences between respondents and non-respondents. The ideas are motivated and illustrated by an analysis of a friendship network from the National Longitudinal Study of Adolescent Health.","tags":["AddHealth","exponential random graph model","maximum likelihood estimation","nonresponse","sample survey","statnet"],"title":"Model-based Assessment of the Impact of Missing Data on Inference for Networks","type":"publication"},{"authors":["Adam Glynn","Jon Wakefield","Mark S. Handcock","Thomas Richardson"],"categories":[],"content":"","date":1125964800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1125964800,"objectID":"23475bb3c21982c18828e5b850d36a24","permalink":"https:handcock.github.io/publication/cssswp_51/","publishdate":"2005-09-06T00:00:00Z","relpermalink":"/publication/cssswp_51/","section":"publication","summary":"In this paper, we illustrate that combining ecological data with subsample data in situations in which a linear model is appropriate provides three main benefits.","tags":["ecological bias","combining information","within-area confounding","returns to education","sample design"],"title":"Alleviating Linear Ecological Bias and Optimal Design with Subsample Data","type":"publication"},{"authors":["Sanjay Chaudhuri","Mark S. Handcock","Michael S. Rendall"],"categories":[],"content":"","date":1115251200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1115251200,"objectID":"472a2edde0208ec3978372c2f81b9d8b","permalink":"https:handcock.github.io/publication/cssswp_48/","publishdate":"2005-05-05T00:00:00Z","relpermalink":"/publication/cssswp_48/","section":"publication","summary":"In many situations information from a sample of individuals can be supplemented by population level information on the relationship between a dependent and explanatory variables. Inclusion of the population level information can reduce bias and increase the efficiency of the parameter estimates. Population level information can be incorporated via constraints on the model parameters. In general the constraints are nonlinear making the task of maximum likelihood estimation harder. In this paper we develop an alternative approach exploiting the notion of an empirical likelihood. It is shown that within the framework of generalised linear models, the population level information corresponds to linear constraints, which are comparatively easy to handle. We provide a two-step algorithm that produces parameter estimates using only unconstrained estimation. We also provide computable expressions for the standard errors. We give an application to demographic hazard modeling by combining panel survey data from the British Household Panel Survey (BHPS) with birth registration data.","tags":["Empirical Likelihood","Constrained Optimisation","Generalised Linear Models"],"title":"Generalised Linear Models Incorporating Population Level Information: An Empirical Likelihood Based Approach","type":"publication"},{"authors":["Mark S. Handcock","Adrian E. Raftery","Jeremy M. Tantrum"],"categories":[],"content":"","date":111456e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":111456e4,"objectID":"4398483472608d6a5ab6fcf3ccf4f673","permalink":"https:handcock.github.io/publication/cssswp_46/","publishdate":"2005-04-27T00:00:00Z","relpermalink":"/publication/cssswp_46/","section":"publication","summary":"Network models are widely used to represent relations among interacting units or actors. Network data often exhibit transitivity, meaning that two actors that have ties to a third actor are more likely to be tied than actors that do not, homophily by attributes of the actors or dyads, and clustering. Interest often focuses on  nding clusters of actors or ties, and the number of groups in the data is typically unknown. We propose a new model, the Latent Position Cluster Model (LPCM), under which the probability of a tie between two actors depends on the distance between them in an unobserved Euclidean social space, and the actors' locations in the latent social space arise from a mixture of distributions, each one corresponding to a cluster. We propose two estimation methods: a two-stage maximum likelihood method, and a Bayesian MCMC method; the former is quicker and simpler, but the latter performs better. We also propose a Bayesian way of determining the number of clusters present using approximate conditional Bayes factors. It models transitivity, homophily by attributes and clustering simultaneously, and does not require the number of clusters to be known. The model makes it easy to simulate realistic networks with clustering, potentially useful as inputs to models of more complex systems of which the network is part, such as epidemic models of infectious disease. We apply the model to two networks of social relations.","tags":["social networks","latent position models","methodology"],"title":"Model-Based Clustering for Social Networks","type":"publication"},{"authors":["William C. Miller","Carol A. Ford","Marcia M. Hobbs","Myron S. Cohen","John L. Schmitz","Kathleen Mullan Harris","Mark S. Handcock","Martina Morris"],"categories":[],"content":"","date":1092787200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1092787200,"objectID":"bef9c5944a76b016ec2b8f2611d52e48","permalink":"https:handcock.github.io/publication/prev-chla-gono-reply/","publishdate":"2004-08-18T00:00:00Z","relpermalink":"/publication/prev-chla-gono-reply/","section":"publication","summary":"This is a reply to Dr Gaydos and colleagues following their comments on our paper 'Prevalence of Chlamydial and Gonococcal Infections among Young Adults', Journal of the American Medical Association, May 12, 2004, 291 (18):2229-2236. DOI: 10.1001/jama.291.18.2229.","tags":["epidemiology"],"title":"Prevalence of Chlamydial and Gonococcal Infections Among Young Adults—Reply","type":"publication"},{"authors":["David R. Hunter","Mark S. Handcock"],"categories":[],"content":"","date":1091491200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1091491200,"objectID":"934137f308f6760e34ec1c44158ac0a8","permalink":"https:handcock.github.io/publication/cssswp_43/","publishdate":"2004-08-03T00:00:00Z","relpermalink":"/publication/cssswp_43/","section":"publication","summary":"Network data arise in a wide variety of applications. Although descriptive statistics for networks abound in the literature, the science of fitting statistical models to complex network data is still in its infancy. The models considered in this article are based on exponential families; therefore, we refer to them as exponential random graph models (ERGMs). Although ERGMs are easy to postulate, maximum likelihood estimation of parameters in these models is very difficult. In this article, we first review the method of maximum likelihood estimation using Markov chain Monte Carlo in the context of fitting linear ERGMs. We then extend this methodology to the situation where the model comes from a curved exponential family. The curved exponential family methodology is applied to new specifications of ERGMs, proposed by Snijders et al. (2004), having non-linear parameters to represent structural properties of networks such as transitivity and heterogeneity of degrees. We review the difficult topic of implementing likelihood ratio tests for these models, then apply all these model-fitting and testing techniques to the estimation of linear and non-linear parameters for a collaboration network between partners in a New England law firm.","tags":["exponential random graph model","maximum likelihood estimation","Markov chain Monte Carlo","p−star model"],"title":"Inference in curved exponential family models for networks","type":"publication"},{"authors":["J. A. Hepinstall","J. M. Marzluff","Mark S. Handcock","P. Hurvitz"],"categories":[],"content":"","date":1086048e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1086048e3,"objectID":"498c9f409ed88224dfce342fe986cc04","permalink":"https:handcock.github.io/publication/hepinstalletal2004/","publishdate":"2004-06-01T00:00:00Z","relpermalink":"/publication/hepinstalletal2004/","section":"publication","summary":"An accurate estimate of resource use by an animal can be summarized by regressing local- and landscape level resources on an individual animal’s or population’s utilization distribution (UD) in a spatially explicit way. The resulting equation is termed a Resource Utilization Function and the regression coefficients indicate the intensity, direction, and consistency of resource use. However, using the UD as a response variable requires sampling individual pixels within the UD, which introduces spatial autocorrelation into the data, potentially affecting results and conclusions regarding resource use by the study animal. We discuss methods to remove the spatial autocorrelation so that the significance of regression coefficients for each resource can be evaluated for each animal. By using this methodology, we are able to quantify the individualistic nature of resource selection and test for consistency in use of resources by a population. We demonstrate the effects of removing spatial autocorrelation on individual parameter estimates of resource use by individual animals using radio telemetry data for 25 radiotagged Steller's jays (Cyanocitta stelleri) in western Washington. The technique of removing spatial autocorrelation from our samples allows the use of pixel-level sampling of the UD in future resource selection studies.","tags":["environmetrics","habitat selection","habitat use","kernel","GIS","multiple regression","resource selection","resource utilization function"," Steller’s jay","spatial autocorrelation","utilization distribution","spatially-autocorrelated regression error"],"title":"Incorporating Utilization Distributions into the Study of Resource Selection: Dealing With Spatial Autocorrelation","type":"publication"},{"authors":["William C. Miller","Carol A. Ford","Martina Morris","Mark S. Handcock","John L. Schmitz","Marcia M. Hobbs","Myron S. Cohen","Kathleen Mullan Harris","J. R. Udry"],"categories":[],"content":"","date":108432e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":108432e4,"objectID":"644dfb26446495f511984d0ab3493667","permalink":"https:handcock.github.io/publication/prev-chla-gono/","publishdate":"2004-05-12T00:00:00Z","relpermalink":"/publication/prev-chla-gono/","section":"publication","summary":"Context: Chlamydial and gonococcal infections are important causes of pelvic inflammatory disease, ectopic pregnancy, and infertility. Although screening for Chlamydia trachomatis is widely recommended among young adult women, little information is available regarding the prevalence of chlamydial and gonococcal infections in the general young adult population. Objective: To determine the prevalence of chlamydial and gonoccoccal infections in a nationally representative sample of young adults living in the United States. Design, Setting, and Participants: Cross-sectional analyses of a prospective cohort study of a nationally representative sample of 14 322 young adults aged 18 to 26 years. In-home interviews were conducted across the United States for Wave III of The National Longitudinal Study of Adolescent Health (Add Health) from April 2, 2001, to May 9, 2002. This study sample represented 66.3% of the original 18 924 participants in Wave I of Add Health. First-void urine specimens using ligase chain reaction assay were available for 12 548 (87.6%) of the Wave III participants. Main Outcome Measures: Prevalences of chlamydial and gonococcal infections in the general young adult population, and by age, self-reported race/ethnicity, and geographic region of current residence. Results: Overall prevalence of chlamydial infection was 4.19% (95% confidence interval [CI], 3.48%-4.90%). Women (4.74%; 95% CI, 3.93%-5.71%) were more likely to be infected than men (3.67%; 95% CI, 2.93%-4.58%; prevalence ratio, 1.29; 95% CI, 1.03-1.63). The prevalence of chlamydial infection was highest among black women (13.95%; 95% CI, 11.25%-17.18%) and black men (11.12%; 95% CI, 8.51%-14.42%); lowest prevalences were among Asian men (1.14%; 95% CI, 0.40%-3.21%), white men (1.38%; 95% CI, 0.93%-2.03%), and white women (2.52%; 95% CI, 1.90%-3.34%). Prevalence of chlamydial infection was highest in the south (5.39%; 95% CI, 4.24%-6.83%) and lowest in the northeast (2.39%; 95% CI, 1.56%-3.65%). Overall prevalence of gonorrhea was 0.43% (95% CI, 0.29%-0.63%). Among black men and women, the prevalence was 2.13% (95% CI, 1.46%-3.10%) and among white young adults, 0.10% (95% CI, 0.03%-0.27%). Prevalence of coinfection with both chlamydial and gonococcal infections was 0.030% (95% CI, 0.18%-0.49%). Conclusions: The prevalence of chlamydial infection is high among young adults in the United States. Substantial racial/ethnic disparities are present in the prevalence of both chlamydial and gonococcal infections.","tags":["epidemiology"],"title":"Prevalence of Chlamydial and Gonococcal Infections Among Young Adults","type":"publication"},{"authors":["David R. Hunter","Steven M. Goodreau","Mark S. Handcock"],"categories":[],"content":"","date":1083110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1083110400,"objectID":"7e07ec24ac5d69d594a7bb387c28c1f0","permalink":"https:handcock.github.io/publication/cssswp_47/","publishdate":"2004-04-28T00:00:00Z","relpermalink":"/publication/cssswp_47/","section":"publication","summary":"We present a systematic examination of real network datasets using maximum likelihood estimation for exponential random graph models as well as new procedures to evaluate how well the models fit the observed graphs. These procedures compare structural statistics of the observed graph with the corresponding statistics on graphs simulated from the fitted model. We apply this approach to the study of friendship relations among high school students from the National Longitudinal Study of Adolescent Health (AddHealth). The sizes of the networks we fit range from 71 to 2209 nodes. The larger networks represent more than an order of magnitude increase over the size of any network previously fit using maximum likelihood methods for models of this kind. We argue that several well-studied models in the networks literature do not fit these data well, and we demonstrate that the fit improves dramatically when the models include the recently-developed geometrically weighted edgewise shared partner (GWESP), geometrically weighted dyadic shared partner (GWDSP), and geometrically weighted degree (GWD) network statistics. We conclude that these models capture aspects of the social structure of adolescent friendship relations not represented by previous models.","tags":["degeneracy","exponential random graph model","maximum likelihood estimation","Markov chain Monte Carlo","p−star model"],"title":"Goodness of Fit of Social Network Models","type":"publication"},{"authors":["Tom A.B. Snijders","Philippa E. Pattison","Garry L. Robins","Mark S. Handcock"],"categories":[],"content":"","date":1082678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1082678400,"objectID":"be0010218e9ffbe5c12d37869ce9940d","permalink":"https:handcock.github.io/publication/cssswp_42/","publishdate":"2004-04-23T00:00:00Z","relpermalink":"/publication/cssswp_42/","section":"publication","summary":"The most promising class of statistical models for expressing structural properties of social networks is the class of Exponential Random Graph Models (ERGMs), also known as $p^*$ models. The strong point of these models is that they can represent structural tendencies, such as transitivity, that define complicated dependence patterns not easily modeled by more basic probability models. Recently, MCMC algorithms have been developed which produce approximate Maximum Likelihood estimators. Applying these models in their traditional specification to observed network data often has led to problems, however, which can be traced back to the fact that important parts of the parameter space correspond to nearly degenerate distributions, which may lead to convergence problems and a poor fit to empirical data. This paper proposes new specifications of the exponential random graph model. These specifications represent structural properties such as transitivity and heterogeneity of degrees by more complicated graph statistics than the traditional star and triangle counts. Three kinds of statistic are proposed: geometrically weighted degree distributions, alternating ktriangles, and alternating independent two-paths. Examples are presented both of modeling graphs and digraphs, in which the new specifications lead to much better results than the earlier existing specifications of the ERGM. It is concluded that the new specifications increase the range and applicability of the ERGM as a tool for the statistical analysis of social networks.","tags":["Statistical modeling","Social networks","Graphs","Transitivity","Clustering","Maximum likelihood","MCMC, p* model"],"title":"New specifications for exponential random graph models","type":"publication"},{"authors":["Susan Shortreed","Mark S. Handcock"],"categories":[],"content":"","date":1081468800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1081468800,"objectID":"3b97b17c2d89dd9078c17b871cb7fc5d","permalink":"https:handcock.github.io/publication/cssswp_41/","publishdate":"2004-04-09T00:00:00Z","relpermalink":"/publication/cssswp_41/","section":"publication","summary":"Recent advances in latent space and related random effects models hold much promise for representing network data. The inherent dependency between ties in a network makes modeling data of this type difficult. In this article we consider a recently developed latent space model that is particularly appropriate for the visualization of networks. We suggest a new estimator of the latent positions and perform two network analyses, comparing four alternative estimators. We demonstrate a method of checking the validity of the positional estimates. These estimators are implemented via a package in the freeware statistical language R. The package allows researchers to efficiently fit the latent space model to data and to visualize the results.","tags":["random graph models","Markov chain Monte Carlo","visualization","maximum likelihood estimation"],"title":"Positional Estimation Within a Latent Space Model for Networks","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":1072915200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1072915200,"objectID":"510ab6b59dc07df225a94f6a140a7f62","permalink":"https:handcock.github.io/publication/reldist-ency/","publishdate":"2004-01-01T00:00:00Z","relpermalink":"/publication/reldist-ency/","section":"publication","summary":"This is a entry in the 'The SAGE encyclopedia of social science research methods', edited by M. S. Lewis-Beck, A. Bryman, and T. Futing Liao on relative distribution methods, which I was creator of. Differences among groups or changes in the distribution of a variable over time are a common focus of study in the social sciences. Traditional parametric models restrict such analyses to conditional means and variances, leaving much of the distributional information untapped. Relative distributional methods aim to move beyond means-based comparisons to conduct detailed analyses of distributional difference. As such, they present a general framework for comparative distributional analysis.","tags":["distributional analysis"],"title":"Relative Distribution Method","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":1072828800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1072828800,"objectID":"0abb0a7e0a873d0629c6659628ae67a5","permalink":"https:handcock.github.io/publication/cssswp_39/","publishdate":"2003-12-31T00:00:00Z","relpermalink":"/publication/cssswp_39/","section":"publication","summary":"This paper presents recent advances in the statistical modeling of random graphs that have an impact on the empirical study of social networks. Statistical exponential family models (Wasserman and Pattison 1996) are a generalization of the Markov random graph models introduced by Frank and Strauss (1986), which in turn are derived from developments in spatial statistics (Besag 1974). These models recognize the complex dependencies within relational data structures. A major barrier to the application of random graph models to social networks has been the lack of a sound statistical theory to evaluate model fit. This problem has at least three aspects: the specification of realistic models, the algorithmic difficulties of the inferential methods, and the assessment of the degree to which the graph structure produced by the models matches that of the data. We discuss these and related issues of the model degeneracy and inferential degeneracy for commonly used estimators.","tags":["Random graph models","log-linear network model","Markov Fields","Markov Chain Monte Carlo","Statistical Exponential Families","Psuedolikelihood"],"title":"Assessing Degeneracy in Statistical Models of Social Networks","type":"publication"},{"authors":["Mark S. Handcock","Michael S. Rendall","Jacob E. Cheadle"],"categories":[],"content":"","date":1064275200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1064275200,"objectID":"d23ef1c5c0ba2c7ee370e2cf916403b0","permalink":"https:handcock.github.io/publication/cssswp_36/","publishdate":"2003-09-23T00:00:00Z","relpermalink":"/publication/cssswp_36/","section":"publication","summary":"Regression coefficients specify the partial effect of a regressor on the dependent variable. Sometimes the bivariate, or limited multivariate relationship of that regressor variable with the dependent variable is known from population-level data. We show here such population-level data can be used to reduce variance and bias about estimates of those regression coefficients from sample survey data. The method of constrained MLE is used to achieve these improvements. Its statistical properties are first described. The method constrains the weighted sum of all the covariate-specific associations (partial effects) of the regressors on the dependent variable to equal the overall population association of one or more regressors. We refer to those regressors whose bivariate or limited multivariate relationships with the dependent variable are constrained by population data as being “directly constrained.” Our study investigates the improvements in the estimation of directly-constrained variables, and also the improvements in the estimation of other regressor variables that may be correlated with the directly-constrained variables, and thus “indirectly-constrained” by the population data. The example application is to the marital fertility of black versus white women. The difference between white and black women's rates of marital fertility, available from population-level data, gives the overall association of race with fertility. The constrained MLE that uses this information both provides a far more powerful statistical test of the partial effect of being black, and purges the test of a bias that would otherwise distort the estimated magnitude of this effect. We find only trivial reductions, however, in the standard errors of the parameters for indirectly-constrained regressors.","tags":["minority group hypothesis","combining data-sets"],"title":"Generalised Linear Models Incorporating Population Level Information: An Empirical Likelihood Based Approach","type":"publication"},{"authors":["Mark S. Handcock","James Holland Jones","Martina Morris"],"categories":[],"content":"","date":1053993600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1053993600,"objectID":"62c62199da9b5e081c74c74fe916ad8d","permalink":"https:handcock.github.io/publication/cssswp_31/","publishdate":"2003-05-27T00:00:00Z","relpermalink":"/publication/cssswp_31/","section":"publication","summary":"Recent work has focused attention on statistical inference for the population distribution of the number of sexual partners based on survey data. The characteristics of these distributions are of interest as components of mathematical models for the transmission dynamics of sexually-transmitted diseases (STDs). Such information can be used both to calibrate theoretical models, to make predictions for real populations, and as a tool for guiding public health policy. Our previous work on this subject has developed likelihood-based statistical methods for inference that allow for low-dimensional, semi-parametric models. Inference has been based on several proposed stochastic process models for the formation of sexual partnership networks. We have also developed model selection criteria to choose between competing models, and assessed the fit of different models to three populations: Uganda, Sweden, and the USA. Throughout this work, we have emphasized the correct assessment of the uncertainty of the estimates based on the data analyzed. We have also widened the question of interest to the limitations of inferences from such data, and the utility of degree-based epidemiological models more generally. In this paper we address further statistical issues that are important in this area, and a number of confusions that have arisen in interpreting our work. In particular, we consider the use of cumulative lifetime partner distributions, heaping and other issues raised by Liljeros et al. in a recent working paper.","tags":["social networks","epidemics","epidemiology"],"title":"On 'Sexual contacts and epidemic thresholds,' models and inference for Sexual partnership distributions","type":"publication"},{"authors":["Mark S. Handcock","James Holland Jones"],"categories":[],"content":"","date":10476e5,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":10476e5,"objectID":"660f5ff39e99c834885766feed241ef8","permalink":"https:handcock.github.io/publication/cssswp_44/","publishdate":"2003-03-14T00:00:00Z","relpermalink":"/publication/cssswp_44/","section":"publication","summary":"Epidemic thresholds in network models of heterogeneous populations characterized by highly right-skewed contact distributions can be very small. When the population is above the threshold, an epidemic is inevitable and conventional control measures to reduce the transmissibility of a pathogen will fail to eradicate it. We consider a two-sex network model for a sexually transmitted disease which assumes random mixing conditional on the degree distribution. We calculate interval estimates for the epidemic threshold for stochastic process models in three human populations based on representative surveys of sexual behavior (Uganda, Sweden, USA). For Uganda and Sweden, the epidemic threshold is greater than zero with high confidence. For the USA, the interval includes zero. We discuss the implications of these findings along with the limitations of epidemic models which assume random mixing.","tags":["social networks","epidemics","epidemiology"],"title":"Interval Estimates for Epidemic Thresholds in Two-Sex Network Models","type":"publication"},{"authors":["Mark S. Handcock","James Holland Jones"],"categories":[],"content":"","date":1043798400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1043798400,"objectID":"b0239f013b6c59f9b9c66b28f901f167","permalink":"https:handcock.github.io/publication/cssswp_29/","publishdate":"2003-01-29T00:00:00Z","relpermalink":"/publication/cssswp_29/","section":"publication","summary":"Sexually-Transmitted Diseases (STDs) constitute a major public health concern. Mathematical models for the transmission dynamics of STDs indicate that heterogeneity in sexual activity level allow them to persist even when the typical behavior of the population would not support endemicity. This insight focuses attention on the distribution of sexual activity level in a population. In this paper, we develop several stochastic process models for the formation of sexual partnership networks. Using likelihood-based model selection procedures, we assess the fit of the different models to three large distributions of sexual partner counts: (1) Rakai, Uganda, (2) Sweden, and (3) the USA. Five of the six single-sex networks were fit best by the negative binomial model. The American women’s network was best fit by a power-law model, the Yule. For most networks, several competing models fit approximately equally well. These results suggest three conclusions: (1) no single unitary process clearly underlies the formation of these sexual networks, (2) behavioral heterogeneity plays an essential role in network structure, (3) substantial model uncertainty exists for sexual network degree distributions. Behavioral research focused on the mechanisms of partnership formation will play an essential role in specifying the best model for empirical degree distributions. We discuss the limitations of inferences from such data, and the utility of degree-based epidemiological models more generally.","tags":["social networks","epidemics","epidemiology"],"title":"Likelihood-Based Inference for Stochastic Models of Sexual Network Formation","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":1041379200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1041379200,"objectID":"69f5cab03eb7efb525515eaf8e9d0971","permalink":"https:handcock.github.io/publication/dyn-degeneracy/","publishdate":"2003-01-01T00:00:00Z","relpermalink":"/publication/dyn-degeneracy/","section":"publication","summary":"This is a paper in the 'Dynamic Social Network Modeling and Analysis', edited by R. Breiger, K. Carley, and P. Pattison. It is the result of the Committee on Human Factors, Board on Behavioral, Cognitive, and Sensory Sciences. National Academy Press: Washington, DC. DOI: 10.17226/10735. This paper presents recent advances in the statistical modeling of random graphs that have an impact on the representation of social networks. We also consider issues related to the estimation of random graph models. For concreteness the focus is cross-sectional social networks. Statistical exponential family models (Wasserman and Pattison, 1996) are a generalization of the Markov random graph models introduced by Frank and Strauss (1986), which in turn derived from developments in spatial statistics (Besag, 1974). These models recognize the complex dependencies within relational data structures. To date, the use of stochastic graph models for networks has been limited by three interrelated factors: the complexity of realistic models, lack of use of simulation studies, and a poor understanding of the properties of inferential methods. We discuss these factors and related issues of the degeneracy of inference for commonly promoted models. As a cornerstone of this development we present a Markov Chain Monte Carlo (MCMC) algorithm for general random graph models. We also review the role of these MCMC algorithms in simulation, likelihood-based inference, identifying degeneracy of inference, and Bayesian formulations.","tags":["Random graph models","Markov Chain Monte Carlo","Bayesian statistics"],"title":"Statistical Models for Social Networks: Inference and Degeneracy","type":"publication"},{"authors":["Mark S. Handcock","Eric M. Aldrich"],"categories":[],"content":"","date":1038700800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1038700800,"objectID":"cf11666c9b13eb1ef6707bdc00441864","permalink":"https:handcock.github.io/publication/cssswp_27/","publishdate":"2002-12-01T00:00:00Z","relpermalink":"/publication/cssswp_27/","section":"publication","summary":"Relative distribution methods are a nonparametric statistical approach to the comparison of distributions. These methods combine the graphical tools of exploratory data analysis with statistical summaries, decomposition, and inference. This report demonstrates software for implementing relative distribution methods within the R statistical package. It describes how to download and install the software, and use it to redo the analysis in the paper 'Relative Distribution Methods' by Mark S. Handcock and Martina Morris, Sociological Methodology, Vol 28, July 1998. The full code, references and links to further resources are provided.","tags":["Empirical Likelihood","Constrained Optimisation","Generalised Linear Models"],"title":"Applying Relative Distribution Methods in R","type":"publication"},{"authors":["James Holland Jones","Mark S. Handcock"],"categories":[],"content":"","date":103464e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":103464e4,"objectID":"0dabfde9f1740bd5d4597f8a5e4f737a","permalink":"https:handcock.github.io/publication/cssswp_23/","publishdate":"2002-10-15T00:00:00Z","relpermalink":"/publication/cssswp_23/","section":"publication","summary":"Recent research into the properties of human sexual contact networks has suggested that the degree distribution of the contact graph exhibits power-law scaling. One notable property of this power-law scaling is that for a range of scaling exponents, the variance of the degree distribution is infinite. This property is of fundamental significance for the control of sexually transmitted diseases (STDs) such as HIV/AIDS since infinite variance of the degree distribution implies no epidemic threshold, and that an STD can persist regardless of its transmissibility. A stochastic process, known as preferential attachment, that yields one form of power law scaling has been suggested to underlie the scaling of sexual degree distributions. The limiting distribution of the preferential attachment process is the Yule distribution, which we fit using maximum likelihood (ML) to local network data for samples of three populations: (1) the Rakai District, Uganda, (2) Sweden, and (3) USA. For all local networks but one, our interval estimates of the scaling parameters do not overlap the range in which Yule distribution has infinite variance. The exponent for male networks in the USA is close to the infinite-variance range, but the preferential attachment model is a very poor fit to these data. We conclude that epidemic thresholds exist in both single-sex and two-sex epidemic model formulations. A strong conclusion we derive from these results is that public health interventions aimed at reducing the transmissibility of STD pathogens, such as implementing condom use or high activity anti-retroviral therapy (HAART), have the potential of bringing a population below the epidemic transition, even in populations exhibiting large degrees of behavioral heterogeneity.","tags":["social networks","epidemics","epidemiology"],"title":"An Assessment of Preferential Attachment as a Mechanism for Human Sexual Network Formation","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":102816e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":102816e4,"objectID":"50a99fee04b4103df20ada1ab5298103","permalink":"https:handcock.github.io/publication/asa02/","publishdate":"2002-08-01T00:00:00Z","relpermalink":"/publication/asa02/","section":"publication","summary":"The assessment of environmental risk and the evaluation of environmental policies increasingly require accurate and relevant information about the environment. For policy makers and stakeholders to evaluate possible policy changes, an understanding of the cause-and-eﬀect relationship between the alternative policies and their environmental and social outcomes is essential. Addressing these questions requires information from diverse sources to be collected, organized, and combined. Evolutionary improvements in Geographic Information Systems (GIS) now routinely allow the management and mapping of spatial-temporal information. However there is a dearth of statistical methodology, not only to represent the complexities of the information, but also to allow the uncertainty of the resulting inference to be quantiﬁed. The development of statistical models to combine information of diﬀerent types and spatial support is of vital importance to environmental social science. The objective of the paper is to improve understanding of the biological integrity of stream and river systems in the United States Mid-Atlantic Region by combining information from separate monitoring surveys, available contextual information on hydrologic units and remote sensing information.","tags":["Spatial statistics","GIS","Hierarchical models","Relative distribution","EMAP"],"title":"Statistical Methods for Ecological Assessment Of Riverine Systems By Combining Information From Multiple Sources","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":1026691200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1026691200,"objectID":"f216cc6ab69cfa8ae67b714b540ddc34","permalink":"https:handcock.github.io/publication/polmeth02/","publishdate":"2002-07-15T00:00:00Z","relpermalink":"/publication/polmeth02/","section":"publication","summary":"The primary objective of this paper is to describe some recent advances in the modeling of random graphs that have an impact on the representation of sexual and drug use networks. We also investigate issues related to the estimation of random graph models. The main focus is cross-sectional social network models, although dynamic or longitudinal models are brieﬂy discussed. Statistical exponential family models (Wasserman and Pattison, 1996) are a generalization of the Markov random graph models introduced by Frank and Strauss (1986), which in turn derived from developments in spatial statistics (Besag, 1974). These models recognize the complex dependencies within relational data structures. To date, the use of stochastic graph models for networks has been limited by three interrelated factors: the complexity of realistic models, lack of use of simulation studies, and a poor understanding of the properties of inferential methods. In this paper we discuss these factors and related issues of the degeneracy of commonly promoted models. As a cornerstone of this development we present a Markov Chain Monte Carlo (MCMC) algorithm for general random graph models. We also review the role of these MCMC algorithms for simulation, addressing model degeneracy, and likelihood-based inference.","tags":["Random graph models","log-linear network model","Markov Fields","Markov Chain Monte Carlo"],"title":"Degeneracy and Inference for Social Network Models","type":"publication"},{"authors":["James Holland Jones","Mark S. Handcock"],"categories":[],"content":"","date":1020211200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1020211200,"objectID":"cd1d908760cac4c9bdb0779758ed830b","permalink":"https:handcock.github.io/publication/cssswp_21/","publishdate":"2002-05-01T00:00:00Z","relpermalink":"/publication/cssswp_21/","section":"publication","summary":"There has been a growing interest in the application of social network theory to the epidemiology of sexually-transmitted diseases (STD). This interest arises from recognition that STDs are transmitted through binary contacts and, consequently, predictions about STD epidemics are unlikely to be robust to the mass-action assumptions of classical mathematical epidemiology. Substantial attention has recently been given to the possibility that human sexual networks exhibit scale-free behavior. We consider scale-free networks that arise when the probability mass function for partner number (i.e., network degree) is given by a power law, $P(k) \\approx k^{−\\alpha}$ , with $2 \u003c \\alpha \\le 3$. Such networks are characterized by a degree distribution with infinite variance, and since the epidemic threshold parameter increases linearly with the variance under behavioral heterogeneity, the epidemic threshold should always be exceeded in such a scale-free system. We derive the maximum likelihood estimator for the scaling exponent in the discrete power-law distribution, and show that the statistical fit of the power-law model is very poor for a large local network data set from Uganda. This finding suggests that human sexual networks may be more complex than simple analogy to computer networks might suggest, and that a more flexible, actor-based approach to modeling sexual networks is required to understand and control STD epidemics.","tags":["social networks","epidemics","epidemiology"],"title":"Statistical Evidence Tells Tails of Human Sexual Contacts","type":"publication"},{"authors":["Annette B. Bernhardt","Martina Morris","Mark S. Handcock","Marc A. Scott"],"categories":[],"content":"","date":993081600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":993081600,"objectID":"ee04e2ba238c0873fc9a71849e9a5aab","permalink":"https:handcock.github.io/publication/book_divergent_paths/","publishdate":"2001-06-21T00:00:00Z","relpermalink":"/publication/book_divergent_paths/","section":"publication","summary":"The promise of upward mobility—the notion that everyone has the chance to get ahead—is one of this country's most cherished ideals, a hallmark of the American Dream. But in today's volatile labor market, the tradition of upward mobility for all may be a thing of the past. In a competitive world of deregulated markets and demanding shareholders, many firms that once offered the opportunity for advancement to workers have remade themselves as leaner enterprises with more flexible work forces. Divergent Paths examines the prospects for upward mobility of workers in this changed economic landscape. Based on an innovative comparison of the fortunes of two generations of young, white men over the course of their careers, Divergent Paths documents the divide between the upwardly mobile and the growing numbers of workers caught in the low-wage trap.\nThe first generation entered the labor market in the late 1960s, a time of prosperity and stability in the U.S. labor market, while the second generation started work in the early 1980s, just as the new labor market was being born amid recession, deregulation, and the weakening of organized labor. Tracking both sets of workers over time, the authors show that the new labor market is more volatile and less forgiving than the labor market of the 1960s and 1970s. Jobs are less stable, and the penalties for failing to find a steady employer are more severe for most workers. At the top of the job pyramid, the new nomads—highly credentialed, well-connected workers—regard each short-term project as a springboard to a better-paying position, while at the bottom, a growing number of retail workers, data entry clerks, and telemarketers, are consigned to a succession of low-paying, dead-end jobs.\nWhile many commentators dismiss public anxieties about job insecurity as overblown, Divergent Paths carefully documents hidden trends in today's job market which confirm many of the public's fears. Despite the celebrated job market of recent years, the authors show that the old labor market of the 1960s and 1970s propelled more workers up the earnings ladder than does today's labor market. Divergent Paths concludes with a discussion of policy strategies, such as regional partnerships linking corporate, union, government, and community resources, which may help repair the career paths that once made upward mobility a realistic ambition for all American workers.","tags":["Complex survey data","Labor Economics","Economic Inequality","data analysis","demography"],"title":"Divergent Paths: Economic Mobility in the New American Labor Market","type":"publication"},{"authors":["A. D. Bernhardt","M. Morris","Mark S. Handcock","M. Scott"],"categories":[],"content":"","date":973036800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":973036800,"objectID":"73c7e200d4a496dc2ae21f7ec6f372a7","permalink":"https:handcock.github.io/publication/on-the-job2000/","publishdate":"2000-11-01T00:00:00Z","relpermalink":"/publication/on-the-job2000/","section":"publication","summary":"This is a paper in 'On the Job: Is Long Term Employment a Thing of the Past?', edited by David Neumark. New York: Russell Sage.","tags":["job instabolity","labor economics","longitudinal data"],"title":"Trends in Job Instability and Wages for Young Adult Men","type":"publication"},{"authors":["Mark S. Handcock","Martina Morris"],"categories":[],"content":"","date":938736e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":938736e3,"objectID":"496f0b453f4c074a98af2f0571ac00cc","permalink":"https:handcock.github.io/publication/book_reldist/","publishdate":"1999-10-01T00:00:00Z","relpermalink":"/publication/book_reldist/","section":"publication","summary":"In social science research, differences among groups or changes over time are a common focus of study. While means and variances are typically the basis for statistical methods used in this research, the underlying social theory often implies properties of distributions that are not well captured by these summary measures. Examples include the current controversies regarding growing inequality in earnings, racial diferences in test scores, socio-economic correlates of birth outcomes, and the impact of smoking on survival and health. The distributional differences that animate the debates in these fields are complex. They comprise the usual mean-shifts and changes in variance, but also more subtle comparisons of changes in the upper and lower tails of distributions. Survey and census data on such attributes contain a wealth of distributional information, but traditional methods of data analysis leave much of this information untapped. In this monograph, we present methods for full comparative distributional analysis. The methods are based on the relative distribution, a nonparametric complete summary of the information required for scale--invariant comparisons between two distributions. The relative distribution provides a general integrated framework for analysis. It offers a graphical component that simplifies exploratory data analysis and display, a statistically valid basis for the development of hypothesis-driven summary measures, and the potential for decomposition that enables one to examine complex hypotheses regarding the origins of distributional changes within and between groups. The monograph is written for data analysts and those interested in measurement, and it can serve as a textbook for a course on distributional methods. The presentation is application oriented.","tags":["Complex survey data","Census","Variance","data analysis","statistical method"],"title":"Relative Distribution Methods in the Social Sciences","type":"publication"},{"authors":["Mark S. Handcock"],"categories":[],"content":"","date":872208e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":872208e3,"objectID":"95219ebd7d68822d954545987cdb8080","permalink":"https:handcock.github.io/publication/isi97/","publishdate":"1997-08-22T00:00:00Z","relpermalink":"/publication/isi97/","section":"publication","summary":"The traditional best linear unbiased prediction procedure ('Kriging') is used in this paper for inference, but within a Bayesian framework. See Brown, Le and Zidek (1994) for an alternative Bayesian formulation. Our approach is to exam how posterior predictive distributions of areal quantities change over time. The objective is to see if there have been changes in areal temperature that are discernible from the year-to-year variation. The approach takes into account the uncertainty about the covariance function expressed in the likelihood surface and ignored by point estimates of the covariance function. These ideas are implemented for the spring temperature over the region in the northern United States based on the stations in the United States historical climatological network reported in Karl, Williams, Quinlan and Boden (1990). The results indicates that there is significant micro-scale variation over a spatially smooth field. There is substantial variation in the spring temperature from year-to-year that is spatially correlated (Figure 1). The areal mean temperature is correspondingly variable and appears to be increasing over the period considered (Figure 2). However, this finding has been confirmed using different statistical approaches (Lettenmaier, Wood and Wallis 1994). It is also evident from this later study that, had other regions or periods been picked, the results would have been quite different.","tags":["Bayesian Statistics","Climate Change","Gaussian Random Fields"],"title":"Spatial–Temporal Modeling of Meteorological Fields with application to Climate Change","type":"publication"},{"authors":["Samprit Chatterjee","Mark S. Handcock","Jeffrey S. Simonoff"],"categories":[],"content":"","date":798768e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":798768e3,"objectID":"2f6eaa2098e8dfc856e8feeb71106850","permalink":"https:handcock.github.io/publication/book_casebook/","publishdate":"1995-04-25T00:00:00Z","relpermalink":"/publication/book_casebook/","section":"publication","summary":"The most effective way to learn statistics is by actively engaging in doing the statistical analysis. This idea drives this casebook. An introductory course in statistics often fails to give the students an idea of the excitement of statistics, and its relevance in the present day world. A considerable amount of material has to be covered, with no complementary time for discussion of real life examples. Students often come away with a blurred impression of formulas, and some words like 'mean,' 'standard deviation,' and 'regression.' The point that statistical analysis is vital to arrive at conclusions in a sensible and rational manner is often neglected. This casebook is an attempt to remedy this deficiency by providing an active resource for classroom use. The book is based on cases that we have developed through almost fifty cumulative years of teaching the introductory statistics course at New York University. We have attempted in this casebook to present cases representing situations and contexts from a diverse set of fields, where statistical analysis is required to arrive at a meaningful conclusion. Topics covered include eruptions of the 'Old Faithful' geyser, the issuance of international adoption visas, the space shuttle Challenger tragedy, patterns in the Dow Jones Industrial Average and Standard and Poor's index, health expenditures of states, random drug and disease testing, baseball free agency, performance of NBA guards, energy consumption of a household, grape yields in a vineyard, and the birth and nursing of a beluga whale calf. All of the datasets are real and complete. Each case is motivated by a question that needs to be answered, and full background material is presented. The statistical analysis flows naturally from the question. The discussion given in the cases attempts to demonstrate the logic of the analysis and emphasize the interactive and iterative nature of the task. The aim of these cases is to show the reader by example that statistical analysis clarifies and throws light on a complex situation. It enables one to draw useful conclusions. Besides the final conclusion, much is learned about the problem during the analysis. The journey, as well as the arrival, matters. In addition to investigation of the specific questions raised by a particular case, we hope that the reader also will develop a feel for the kind of approach to data analysis that is likely to be fruitful in general. As statistical software has become generally available, the possibilities of superficial, but inadequate, analysis of data have increased correspondingly. However, if a data analyst is trained to develop a system of general principles in performing a data analysis that are widely applicable, it is much more likely that she will analyze future data sets in a reasonable way. It is our hope that this casebook can be helpful in highlighting the kinds of questions that need to be answered if such a system is being used.","tags":["teaching","data analysis","visualization"],"title":"A Casebook for a First Course in Statistics and Data Analysis","type":"publication"},{"authors":["F. Michelassi","W. Pomidor","A. G. Montag","J. Stephens","R. D. Goldberg","Mark S. Handcock"],"categories":[],"content":"","date":702086400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":702086400,"objectID":"25650d04d3b6b80dc2766b7b1b4f9f3f","permalink":"https:handcock.github.io/publication/michelassi92/","publishdate":"1992-04-01T00:00:00Z","relpermalink":"/publication/michelassi92/","section":"publication","summary":"Semiquantitative immunohistochemical assays have been used with increasing frequency. This study was designed to investigate the reproducibility of such measurements by observing how the measured level varied du.e to (a) the choice of tissue sample from a single or multiple tumors, (b) the immunohistochemical procedure and the influence of time on staining and (c) the subjective variability between readers (interobserver) and by the same reader (intra-observer). The study was meant to judge the reproducibility of the method, not its accuracy. The choice of the monoclonal antibody therefore did not influence the results. A total of 128 sets of sljdes from 8 colonic adenocarcinomas were analyzed by three pathologists using a randomized, symmetric, prospective, doubleblind study. There was surprisingly poor agreement between readings of the same case by the three pathologists (37%) and by the same pathologist over time (58%). Based on the component of variation analysis, 11% of the total variation was due to differences in the immunohistochemical procedure, 5% to variation of expression in different tumors, 5% to interobserver and 79% to intra-observer variability. Readings of semiquantitative immunohistochemical assays is limited by subjective intrinsic variability.","tags":["biostatistics","Immunohistochemistry","assay","Adenocarcinoma"],"title":"Quantification of Variation in Reading Immunohistochemical Assays","type":"publication"},{"authors":["F. Michelassi","J. A. Hayman","Mark S. Handcock","R. Goldberg","F. Erroi","B. A. Lashner","S. B. Hanauer"],"categories":[],"content":"","date":657417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":657417600,"objectID":"3b4711dc00256bc443269aebc7e351c8","permalink":"https:handcock.github.io/publication/michelassi90/","publishdate":"1990-11-01T00:00:00Z","relpermalink":"/publication/michelassi90/","section":"publication","summary":"Increased expression of cellular oncogenes has been linked to malignant-transformation. To investigate the role of oncogenes in the malignant transformation of colonic epithelium in ulcerative colitis, we compared the levels of ras oncogene protein product (p2l) in specimens of normal human colonic mucosa (n=16) with levels in specimens ofukerative colitis with inactive (n=11) and active disease (n=11), low- (n=17) and high-grade dysplasia (n=9) and adenocarcinoma (n=13). p21 content was measured using the RAP-S monoclonal antibody in a semi-quantitative immunohistochemical assay. Titer was expressed as the highest serial dilution of antibody giving definite staining with the avidin-biotin peroxidase method. There were no statistically significant differences between ras p21-levels of low-grade and high-grade dysplasia, of active and inactive ulcerative colitis, and of ulcerative colitis with and without dysplasia. Differences in p21 titer values between normal colonic mucosa, ulcerative colitis without adenocarcinoma and adenocarcinoma in ulcerative colitis were statistically significant using Fisher's exact test (normal colonic mucosa \u003c ulcerative colitis \u003c adenocarcinoma in ulcerative colitis; all p \u003c 0.05). We conclude that p21 levels in ulcerative colitis are higher than in normal colonic mucosa and that they further increase in adenocarcinoma complicating ulcerative colitis - thus suggesting an important role for the ras oncogene in the associated malignant transformation.","tags":["biostatistics","Ras oncogene","Ulcerative colitis"],"title":"Ras Oncogene Protein Product in Ulcerative Colitis","type":"publication"},{"authors":["F. Michelassi","G. Grad","F. Erroi","M. Roncella","J. Romagnoli","Mark S. Handcock"],"categories":[],"content":"","date":654739200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":654739200,"objectID":"d8ad08238ebf45437a8cc265bb3c4415","permalink":"https:handcock.github.io/publication/michelassi90hep/","publishdate":"1990-10-01T00:00:00Z","relpermalink":"/publication/michelassi90hep/","section":"publication","summary":"In order to investigate the value of ras oncogene expression as a prognostic indicator in colonic adenocarcinoma, we evaluated the level of ras gene protein product (p21) in the available material of 109 surgical specimens resected at our institution between 1978 and 1981. Pathology slides and archived paraffin blocks were retrieved for confirmation of the original diagnosis, determination of stage, and measurement of p21 content. P21 titers were obtained using the RAP-5 monoclonal antibody in a semiquantitative immunohistochemical assay. Titer was expressed as the highest dilution of antibody given definitive staining using the Avidin-Biotin peroxidase method. The analysis indicated that tumors with high ( \u003e 1:40,000) p21 titer had a lower five-year survival rate than tumors with low ( \u003c 1:40,000) titers (34.3% vs 60.8%, p \u003c 0.02). When a logistic regression analysis was used with the dependent variable being five-year survival and the independent variables being age, sex, location of tumor, Dukes' stage, mucin production, p21 titer, differentiation degree and tumor size, the statistically significant relationship of the level of ras gene protein product to long-term survival was negated by the concomitant knowledge of Dukes' stage. On the other hand, when only the variables available in the preoperative period were entered in the multivariate analysis, p21 titers retained a significant relationship with long-term survival (p \u003c 0.05). We conclude that ras oncogene determination in colonic carcinomas may have importance for the pre-operative identification of a group of colonic tumors with a more aggressive behavior and a poorer prognosis.","tags":["biostatistics","Colon","Carcinoma","Prognosis","Rasoncogene expression"],"title":"Relationship between Ras Oncogene Expression and Clinical and Pathological Features of Colonic Carcinoma","type":"publication"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"6f2ae24689dd626422f36a03d187ca38","permalink":"https:handcock.github.io/featured/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/featured/","section":"","summary":"Publications","tags":null,"title":"","type":"widget_page"}]